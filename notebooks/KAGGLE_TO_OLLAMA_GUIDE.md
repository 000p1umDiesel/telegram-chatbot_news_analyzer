# ๐ ะะฝัะตะณัะฐัะธั ะผะพะดะตะปะธ ะธะท Kaggle ะฒ Ollama

ะะพัะฐะณะพะฒะพะต ััะบะพะฒะพะดััะฒะพ ะฟะพ ะทะฐะณััะทะบะต ะดะพะพะฑััะตะฝะฝะพะน ะฒ Kaggle ะผะพะดะตะปะธ ะฒ Ollama ะดะปั ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะฒ ะฒะฐัะตะผ ะฟัะพะตะบัะต.

## ๐ ะกะพะดะตัะถะฐะฝะธะต

1. [ะะพะดะณะพัะพะฒะบะฐ ะผะพะดะตะปะธ ะฒ Kaggle](#1-ะฟะพะดะณะพัะพะฒะบะฐ-ะผะพะดะตะปะธ-ะฒ-kaggle)
2. [ะกะบะฐัะธะฒะฐะฝะธะต ะผะพะดะตะปะธ](#2-ัะบะฐัะธะฒะฐะฝะธะต-ะผะพะดะตะปะธ)
3. [ะกะพะทะดะฐะฝะธะต Ollama ะผะพะดะตะปะธ](#3-ัะพะทะดะฐะฝะธะต-ollama-ะผะพะดะตะปะธ)
4. [ะะฝัะตะณัะฐัะธั ะฒ ะฟัะพะตะบั](#4-ะธะฝัะตะณัะฐัะธั-ะฒ-ะฟัะพะตะบั)
5. [ะขะตััะธัะพะฒะฐะฝะธะต](#5-ัะตััะธัะพะฒะฐะฝะธะต)

---

## 1. ๐ ะะพะดะณะพัะพะฒะบะฐ ะผะพะดะตะปะธ ะฒ Kaggle

### ะะฑััะตะฝะธะต ะผะพะดะตะปะธ

ะัะฟะพะปัะทัะนัะต ัะพะทะดะฐะฝะฝัะน `kaggle_finetuning.ipynb` notebook ะฒ Kaggle. ะะฝ ะฐะฒัะพะผะฐัะธัะตัะบะธ:

1. **ะะฐะณััะถะฐะตั ะดะฐะฝะฝัะต** ะธะท ะฒะฐัะตะณะพ dataset
2. **ะะฑััะฐะตั ะผะพะดะตะปั** ั LoRA
3. **ะะฑัะตะดะธะฝัะตั LoRA** ั ะฑะฐะทะพะฒะพะน ะผะพะดะตะปัั
4. **ะกะพะทะดะฐะตั ะฐััะธะฒ** `saiga_hashtag_model_for_ollama.zip`
5. **ะะพะดะณะพัะฐะฒะปะธะฒะฐะตั Modelfile** ะดะปั Ollama

ะะพัะปะต ะทะฐะฒะตััะตะฝะธั ะพะฑััะตะฝะธั ัะบะฐัะฐะนัะต ะณะพัะพะฒัะน ะฐััะธะฒ ะธะท ัะฐะทะดะตะปะฐ Output ะฒ Kaggle.

---

## 2. ๐ฅ ะกะบะฐัะธะฒะฐะฝะธะต ะผะพะดะตะปะธ

### ะงะตัะตะท Kaggle Output

1. ะ Kaggle notebook ะฟะตัะตะนะดะธัะต ะฒ ัะฐะทะดะตะป **Output**
2. ะกะบะฐัะฐะนัะต ัะฐะนะป `saiga_hashtag_model_for_ollama.zip`
3. ะะฐัะฟะฐะบัะนัะต ะฐััะธะฒ ะฝะฐ ะปะพะบะฐะปัะฝะพะน ะผะฐัะธะฝะต

**ะัะธะผะตัะฐะฝะธะต:** ะััะธะฒ ัะถะต ัะพะดะตัะถะธั ะฒัั ะฝะตะพะฑัะพะดะธะผะพะต: ะผะพะดะตะปั, ัะพะบะตะฝะธะทะฐัะพั, Modelfile ะธ ะธะฝััััะบัะธะธ.

---

## 3. ๐ ะกะพะทะดะฐะฝะธะต Ollama ะผะพะดะตะปะธ

### ะกะพะทะดะฐะฝะธะต ะผะพะดะตะปะธ ะฒ Ollama

ะััะธะฒ ัะถะต ัะพะดะตัะถะธั ะณะพัะพะฒัะน Modelfile, ะฟัะพััะพ ะฒัะฟะพะปะฝะธัะต ะบะพะผะฐะฝะดั:

```bash
# ะะฐัะฟะฐะบัะนัะต ะฐััะธะฒ ะธ ะฟะตัะตะนะดะธัะต ะฒ ะฟะฐะฟะบั
unzip saiga_hashtag_model_for_ollama.zip
cd final_model_for_ollama

# ะกะพะทะดะฐะนัะต ะผะพะดะตะปั ะฒ Ollama
ollama create saiga-hashtag-pro -f Modelfile

# ะัะพะฒะตัััะต ัะพะทะดะฐะฝะธะต
ollama list
```

---

## 4. ๐ง ะะฝัะตะณัะฐัะธั ะฒ ะฟัะพะตะบั

### ะะฑะฝะพะฒะปะตะฝะธะต analyzer.py

ะะฑะฝะพะฒะธัะต ัะฐะนะป `services/llm/analyzer.py`:

```python
from ollama import AsyncClient
from core.config import get_settings

settings = get_settings()

class LLMAnalyzer:
    def __init__(self):
        self.ollama_client = AsyncClient(host=settings.OLLAMA_BASE_URL)
        
        # ะะพะดะตะปะธ ะดะปั ัะฐะทะฝัั ะทะฐะดะฐั
        self.models = {
            'original': settings.OLLAMA_MODEL,  # ilyagusev/saiga_llama3
            'hashtag_enhanced': 'saiga-hashtag-pro'  # ะะฐัะฐ ะดะพะพะฑััะตะฝะฝะฐั ะผะพะดะตะปั
        }
        
        # ะคะปะฐะณ ะธัะฟะพะปัะทะพะฒะฐะฝะธั ัะปัััะตะฝะฝะพะน ะผะพะดะตะปะธ
        self.use_enhanced_hashtag_model = True
    
    async def generate_hashtags(self, text: str) -> str:
        """ะะตะฝะตัะธััะตั ัะตััะตะณะธ ั ะฒัะฑะพัะพะผ ะผะพะดะตะปะธ"""
        
        # ะัะฑะธัะฐะตะผ ะผะพะดะตะปั
        model_name = (
            self.models['hashtag_enhanced'] 
            if self.use_enhanced_hashtag_model 
            else self.models['original']
        )
        
        try:
            response = await self.ollama_client.generate(
                model=model_name,
                prompt=f"ะกะณะตะฝะตัะธััะน ัะตััะตะณะธ ะดะปั ะฝะพะฒะพััะธ: {text}",
                options={
                    "temperature": 0.1,
                    "top_p": 0.9,
                    "num_predict": 50
                }
            )
            
            hashtags = response['response'].strip()
            
            # ะัะธััะบะฐ ะธ ัะพัะผะฐัะธัะพะฒะฐะฝะธะต
            hashtags = self._clean_hashtags(hashtags)
            
            return hashtags
            
        except Exception as e:
            # Fallback ะฝะฐ ะพัะธะณะธะฝะฐะปัะฝัั ะผะพะดะตะปั
            if self.use_enhanced_hashtag_model:
                print(f"โ๏ธ ะัะธะฑะบะฐ enhanced ะผะพะดะตะปะธ, ะฟะตัะตะบะปััะฐะตะผัั ะฝะฐ ะพัะธะณะธะฝะฐะปัะฝัั: {e}")
                response = await self.ollama_client.generate(
                    model=self.models['original'],
                    prompt=f"ะกะณะตะฝะตัะธััะน ัะตััะตะณะธ ะดะปั ะฝะพะฒะพััะธ: {text}"
                )
                return self._clean_hashtags(response['response'])
            else:
                raise e
    
    def _clean_hashtags(self, hashtags: str) -> str:
        """ะัะธัะฐะตั ะธ ัะพัะผะฐัะธััะตั ัะตััะตะณะธ"""
        # ะฃะฑะธัะฐะตะผ ะปะธัะฝะธะต ัะธะผะฒะพะปั
        hashtags = hashtags.replace('#', '').strip()
        
        # ะะฐะทะดะตะปัะตะผ ะธ ะพัะธัะฐะตะผ
        tags = [tag.strip() for tag in hashtags.split(',')]
        tags = [tag for tag in tags if tag and len(tag) > 2]
        
        # ะะณัะฐะฝะธัะธะฒะฐะตะผ ะบะพะปะธัะตััะฒะพ
        tags = tags[:5]
        
        return ', '.join(tags)
    
    async def switch_model(self, use_enhanced: bool = True):
        """ะะตัะตะบะปััะฐะตั ะผะตะถะดั ะผะพะดะตะปัะผะธ"""
        self.use_enhanced_hashtag_model = use_enhanced
        model_name = (
            self.models['hashtag_enhanced'] 
            if use_enhanced 
            else self.models['original']
        )
        print(f"๐ ะะตัะตะบะปััะตะฝะพ ะฝะฐ ะผะพะดะตะปั: {model_name}")
```

### ะะพะฑะฐะฒะปะตะฝะธะต ะบะพะผะฐะฝะดั ะฟะตัะตะบะปััะตะฝะธั ะฒ ะฑะพัะฐ

ะ `bot/handlers.py` ะดะพะฑะฐะฒััะต ะบะพะผะฐะฝะดั:

```python
@dp.message(Command("switch_model"))
async def switch_model_command(message: types.Message):
    """ะะตัะตะบะปััะฐะตั ะผะตะถะดั ะผะพะดะตะปัะผะธ ะณะตะฝะตัะฐัะธะธ ัะตััะตะณะพะฒ"""
    
    args = message.text.split()
    if len(args) < 2:
        await message.reply(
            "ะัะฟะพะปัะทะพะฒะฐะฝะธะต: /switch_model enhanced|original\n"
            "enhanced - ะดะพะพะฑััะตะฝะฝะฐั ะผะพะดะตะปั\n"
            "original - ะพัะธะณะธะฝะฐะปัะฝะฐั ะผะพะดะตะปั"
        )
        return
    
    model_type = args[1].lower()
    
    if model_type == "enhanced":
        await analyzer.switch_model(use_enhanced=True)
        await message.reply("โ ะะตัะตะบะปััะตะฝะพ ะฝะฐ ะดะพะพะฑััะตะฝะฝัั ะผะพะดะตะปั")
    elif model_type == "original":
        await analyzer.switch_model(use_enhanced=False)
        await message.reply("โ ะะตัะตะบะปััะตะฝะพ ะฝะฐ ะพัะธะณะธะฝะฐะปัะฝัั ะผะพะดะตะปั")
    else:
        await message.reply("โ ะะตะฒะตัะฝัะน ัะธะฟ ะผะพะดะตะปะธ. ะัะฟะพะปัะทัะนัะต: enhanced ะธะปะธ original")
```

---

## 5. ๐งช ะขะตััะธัะพะฒะฐะฝะธะต

### ะะพะผะฐะฝะดั ะดะปั ัะตััะธัะพะฒะฐะฝะธั

```bash
# ะัะพะฒะตัะบะฐ ัะฟะธัะบะฐ ะผะพะดะตะปะตะน
ollama list

# ะขะตััะธัะพะฒะฐะฝะธะต ะผะพะดะตะปะธ ะฝะฐะฟััะผัั
ollama run saiga-hashtag-pro "ะกะณะตะฝะตัะธััะน ัะตััะตะณะธ ะดะปั ะฝะพะฒะพััะธ: ะฆะตะฝััะฐะปัะฝัะน ะฑะฐะฝะบ ะฟะพะฒััะธะป ะบะปััะตะฒัั ััะฐะฒะบั"

# ะัะพะฒะตัะบะฐ ัะฐะทะผะตัะฐ ะผะพะดะตะปะธ
ollama show saiga-hashtag-pro
```

### ะขะตััะธัะพะฒะฐะฝะธะต ะฒ ะฟัะพะตะบัะต

ะกะพะทะดะฐะนัะต ัะตััะพะฒัะน ัะบัะธะฟั `test_enhanced_model.py`:

```python
import asyncio
from services.llm.analyzer import LLMAnalyzer

async def test_models():
    analyzer = LLMAnalyzer()
    
    test_text = "ะฆะตะฝััะฐะปัะฝัะน ะฑะฐะฝะบ ะะพััะธะธ ะฟะพะฒััะธะป ะบะปััะตะฒัั ััะฐะฒะบั ะดะพ 21% ะณะพะดะพะฒัั"
    
    print("๐งช ะขะตััะธัะพะฒะฐะฝะธะต ะผะพะดะตะปะตะน...")
    print(f"๐ฐ ะขะตะบัั: {test_text}")
    
    # ะขะตัั ะพัะธะณะธะฝะฐะปัะฝะพะน ะผะพะดะตะปะธ
    await analyzer.switch_model(use_enhanced=False)
    original_hashtags = await analyzer.generate_hashtags(test_text)
    print(f"๐ต ะัะธะณะธะฝะฐะปัะฝะฐั: {original_hashtags}")
    
    # ะขะตัั ะดะพะพะฑััะตะฝะฝะพะน ะผะพะดะตะปะธ
    await analyzer.switch_model(use_enhanced=True)
    enhanced_hashtags = await analyzer.generate_hashtags(test_text)
    print(f"๐ข ะะพะพะฑััะตะฝะฝะฐั: {enhanced_hashtags}")

if __name__ == "__main__":
    asyncio.run(test_models())
```

ะะฐะฟัััะธัะต ัะตัั:

```bash
python test_enhanced_model.py
```

---

## 6. ๐ ะะพะฝะธัะพัะธะฝะณ ะธ ััะฐะฒะฝะตะฝะธะต

### ะะพะฑะฐะฒะปะตะฝะธะต ะปะพะณะธัะพะฒะฐะฝะธั

ะ `analyzer.py` ะดะพะฑะฐะฒััะต ะปะพะณะธัะพะฒะฐะฝะธะต ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะผะพะดะตะปะตะน:

```python
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class LLMAnalyzer:
    def __init__(self):
        # ... ัััะตััะฒัััะธะน ะบะพะด ...
        self.model_usage_stats = {
            'original': 0,
            'enhanced': 0
        }
    
    async def generate_hashtags(self, text: str) -> str:
        model_type = 'enhanced' if self.use_enhanced_hashtag_model else 'original'
        self.model_usage_stats[model_type] += 1
        
        start_time = datetime.now()
        
        # ... ะณะตะฝะตัะฐัะธั ัะตััะตะณะพะฒ ...
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info(f"Model: {model_type}, Duration: {duration:.2f}s, Text length: {len(text)}")
        
        return hashtags
    
    def get_usage_stats(self):
        """ะะพะทะฒัะฐัะฐะตั ััะฐัะธััะธะบั ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะผะพะดะตะปะตะน"""
        total = sum(self.model_usage_stats.values())
        if total == 0:
            return self.model_usage_stats
        
        return {
            'original': {
                'count': self.model_usage_stats['original'],
                'percentage': self.model_usage_stats['original'] / total * 100
            },
            'enhanced': {
                'count': self.model_usage_stats['enhanced'],
                'percentage': self.model_usage_stats['enhanced'] / total * 100
            },
            'total': total
        }
```

### ะะพะผะฐะฝะดะฐ ััะฐัะธััะธะบะธ ะฒ ะฑะพัะต

```python
@dp.message(Command("model_stats"))
async def model_stats_command(message: types.Message):
    """ะะพะบะฐะทัะฒะฐะตั ััะฐัะธััะธะบั ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะผะพะดะตะปะตะน"""
    
    stats = analyzer.get_usage_stats()
    
    response = "๐ ะกัะฐัะธััะธะบะฐ ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะผะพะดะตะปะตะน:\n\n"
    response += f"๐ต ะัะธะณะธะฝะฐะปัะฝะฐั: {stats['original']['count']} ({stats['original']['percentage']:.1f}%)\n"
    response += f"๐ข ะะพะพะฑััะตะฝะฝะฐั: {stats['enhanced']['count']} ({stats['enhanced']['percentage']:.1f}%)\n"
    response += f"๐ ะัะตะณะพ ะทะฐะฟัะพัะพะฒ: {stats['total']}"
    
    await message.reply(response)
```

---

## 7. ๐ ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะฒะพะทะผะพะถะฝะพััะธ

### A/B ัะตััะธัะพะฒะฐะฝะธะต

```python
import random

class LLMAnalyzer:
    def __init__(self):
        # ... ัััะตััะฒัััะธะน ะบะพะด ...
        self.ab_test_enabled = False
        self.ab_test_ratio = 0.5  # 50% ะฝะฐ ะบะฐะถะดัั ะผะพะดะตะปั
    
    async def generate_hashtags_with_ab_test(self, text: str) -> dict:
        """ะะตะฝะตัะธััะตั ัะตััะตะณะธ ั A/B ัะตััะธัะพะฒะฐะฝะธะตะผ"""
        
        if not self.ab_test_enabled:
            hashtags = await self.generate_hashtags(text)
            return {
                'hashtags': hashtags,
                'model_used': 'enhanced' if self.use_enhanced_hashtag_model else 'original'
            }
        
        # A/B ัะตัั
        use_enhanced = random.random() < self.ab_test_ratio
        
        # ะัะตะผะตะฝะฝะพ ะฟะตัะตะบะปััะฐะตะผ ะผะพะดะตะปั
        original_setting = self.use_enhanced_hashtag_model
        self.use_enhanced_hashtag_model = use_enhanced
        
        hashtags = await self.generate_hashtags(text)
        
        # ะะพะทะฒัะฐัะฐะตะผ ะธััะพะดะฝัั ะฝะฐัััะพะนะบั
        self.use_enhanced_hashtag_model = original_setting
        
        return {
            'hashtags': hashtags,
            'model_used': 'enhanced' if use_enhanced else 'original',
            'ab_test': True
        }
```

### ะะฒัะพะผะฐัะธัะตัะบะพะต ะฟะตัะตะบะปััะตะฝะธะต ะฟะพ ะบะฐัะตััะฒั

```python
class LLMAnalyzer:
    def __init__(self):
        # ... ัััะตััะฒัััะธะน ะบะพะด ...
        self.quality_threshold = 0.7
        self.auto_switch_enabled = False
    
    async def generate_hashtags_with_quality_check(self, text: str) -> str:
        """ะะตะฝะตัะธััะตั ัะตััะตะณะธ ั ะฟัะพะฒะตัะบะพะน ะบะฐัะตััะฒะฐ"""
        
        if not self.auto_switch_enabled:
            return await self.generate_hashtags(text)
        
        # ะัะพะฑัะตะผ ะดะพะพะฑััะตะฝะฝัั ะผะพะดะตะปั
        enhanced_hashtags = await self._generate_with_model(text, use_enhanced=True)
        quality_score = self._calculate_quality_score(text, enhanced_hashtags)
        
        if quality_score >= self.quality_threshold:
            return enhanced_hashtags
        else:
            # Fallback ะฝะฐ ะพัะธะณะธะฝะฐะปัะฝัั
            logger.warning(f"Low quality score: {quality_score}, switching to original model")
            return await self._generate_with_model(text, use_enhanced=False)
    
    def _calculate_quality_score(self, text: str, hashtags: str) -> float:
        """ะัะพััะฐั ะพัะตะฝะบะฐ ะบะฐัะตััะฒะฐ ัะตััะตะณะพะฒ"""
        # ะะพะถะฝะพ ัะปัััะธัั ััั ะปะพะณะธะบั
        
        tags = hashtags.split(',')
        
        # ะะฐะทะพะฒัะต ะฟัะพะฒะตัะบะธ
        if len(tags) < 2 or len(tags) > 6:
            return 0.3
        
        # ะัะพะฒะตัะบะฐ ะฝะฐ ัะตะปะตะฒะฐะฝัะฝะพััั (ะฟัะพััะฐั)
        text_lower = text.lower()
        relevant_count = 0
        
        for tag in tags:
            tag_clean = tag.strip().lower()
            if any(word in text_lower for word in tag_clean.split()):
                relevant_count += 1
        
        relevance_score = relevant_count / len(tags)
        
        # ะัะพะฒะตัะบะฐ ะฝะฐ ัะฐะทะฝะพะพะฑัะฐะทะธะต
        unique_words = set()
        for tag in tags:
            unique_words.update(tag.strip().lower().split())
        
        diversity_score = len(unique_words) / (len(tags) * 2)  # ะัะธะผะตัะฝะฐั ะผะตััะธะบะฐ
        
        return (relevance_score + diversity_score) / 2
```

---

## 8. ๐ฏ ะัะพะณะพะฒะฐั ััะตะผะฐ ะธะฝัะตะณัะฐัะธะธ

```
โโโโโโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโโโโโ
โ     Kaggle      โโโโโโ  ะกะบะฐัะธะฒะฐะฝะธะต      โโโโโโ   ะะพะบะฐะปัะฝะฐั     โ
โ   (ะะฑััะตะฝะธะต)    โ    โ   ะผะพะดะตะปะธ         โ    โ    ะผะฐัะธะฝะฐ       โ
โโโโโโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโโโโโ
                                                         โ
                                                         โผ
                                               โโโโโโโโโโโโโโโโโโโ
                                               โ     Ollama      โ
                                               โ (saiga-hashtag- โ
                                               โ      pro)       โ
                                               โโโโโโโโโโโโโโโโโโโ
                                                         โ
                                                         โผ
                                               โโโโโโโโโโโโโโโโโโโ
                                               โ  ะะฐั ะฟัะพะตะบั     โ
                                               โ  (analyzer.py)  โ
                                               โโโโโโโโโโโโโโโโโโโ
```

## ๐ ะะตะทัะปััะฐั

ะะพัะปะต ะฒัะฟะพะปะฝะตะฝะธั ะฒัะตั ัะฐะณะพะฒ ั ะฒะฐั ะฑัะดะตั:

โ **ะะพะพะฑััะตะฝะฝะฐั ะผะพะดะตะปั ะฒ Ollama** ะฟะพะด ะธะผะตะฝะตะผ `saiga-hashtag-pro`  
โ **ะะฝัะตะณัะฐัะธั ะฒ ัััะตััะฒัััะธะน ะฟัะพะตะบั** ั ะฒะพะทะผะพะถะฝะพัััั ะฟะตัะตะบะปััะตะฝะธั  
โ **ะะพะผะฐะฝะดั ัะฟัะฐะฒะปะตะฝะธั** ัะตัะตะท Telegram ะฑะพัะฐ  
โ **ะะพะฝะธัะพัะธะฝะณ ะธ ััะฐัะธััะธะบะฐ** ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะผะพะดะตะปะตะน  
โ **A/B ัะตััะธัะพะฒะฐะฝะธะต** ะดะปั ััะฐะฒะฝะตะฝะธั ะบะฐัะตััะฒะฐ  
โ **ะะฒัะพะผะฐัะธัะตัะบะพะต ะฟะตัะตะบะปััะตะฝะธะต** ะฟะพ ะบะฐัะตััะฒั (ะพะฟัะธะพะฝะฐะปัะฝะพ)

ะขะตะฟะตัั ะฒะฐัะฐ ัะธััะตะผะฐ ะผะพะถะตั ะธัะฟะพะปัะทะพะฒะฐัั ะบะฐะบ ะพัะธะณะธะฝะฐะปัะฝัั ะผะพะดะตะปั, ัะฐะบ ะธ ัะฟะตัะธะฐะปัะฝะพ ะดะพะพะฑััะตะฝะฝัั ะดะปั ะณะตะฝะตัะฐัะธะธ ัะตััะตะณะพะฒ! 