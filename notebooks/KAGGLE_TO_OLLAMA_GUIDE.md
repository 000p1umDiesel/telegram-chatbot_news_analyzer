# üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ Kaggle –≤ Ollama

–ü–æ—à–∞–≥–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –≤ Kaggle –º–æ–¥–µ–ª–∏ –≤ Ollama –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤–∞—à–µ–º –ø—Ä–æ–µ–∫—Ç–µ.

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –≤ Kaggle](#1-–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–º–æ–¥–µ–ª–∏-–≤-kaggle)
2. [–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏](#2-—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ-–º–æ–¥–µ–ª–∏)
3. [–°–æ–∑–¥–∞–Ω–∏–µ Ollama –º–æ–¥–µ–ª–∏](#3-—Å–æ–∑–¥–∞–Ω–∏–µ-ollama-–º–æ–¥–µ–ª–∏)
4. [–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–æ–µ–∫—Ç](#4-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è-–≤-–ø—Ä–æ–µ–∫—Ç)
5. [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ](#5-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)

---

## 1. üìö –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –≤ Kaggle

### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–π `kaggle_finetuning.ipynb` notebook –≤ Kaggle. –û–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:

1. **–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ** –∏–∑ –≤–∞—à–µ–≥–æ dataset
2. **–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å** —Å LoRA
3. **–û–±—ä–µ–¥–∏–Ω—è–µ—Ç LoRA** —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
4. **–°–æ–∑–¥–∞–µ—Ç –∞—Ä—Ö–∏–≤** `saiga_hashtag_model_for_ollama.zip`
5. **–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç Modelfile** –¥–ª—è Ollama

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Å–∫–∞—á–∞–π—Ç–µ –≥–æ—Ç–æ–≤—ã–π –∞—Ä—Ö–∏–≤ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ Output –≤ Kaggle.

---

## 2. üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### –ß–µ—Ä–µ–∑ Kaggle Output

1. –í Kaggle notebook –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª **Output**
2. –°–∫–∞—á–∞–π—Ç–µ —Ñ–∞–π–ª `saiga_hashtag_model_for_ollama.zip`
3. –†–∞—Å–ø–∞–∫—É–π—Ç–µ –∞—Ä—Ö–∏–≤ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ê—Ä—Ö–∏–≤ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—ë –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ: –º–æ–¥–µ–ª—å, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, Modelfile –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.

---

## 3. üöÄ –°–æ–∑–¥–∞–Ω–∏–µ Ollama –º–æ–¥–µ–ª–∏

### –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ Ollama

–ê—Ä—Ö–∏–≤ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≥–æ—Ç–æ–≤—ã–π Modelfile, –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—ã:

```bash
# –†–∞—Å–ø–∞–∫—É–π—Ç–µ –∞—Ä—Ö–∏–≤ –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ø–∞–ø–∫—É
unzip saiga_hashtag_model_for_ollama.zip
cd final_model_for_ollama

# –°–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å –≤ Ollama
ollama create saiga-hashtag-pro -f Modelfile

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ
ollama list
```

---

## 4. üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–æ–µ–∫—Ç

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ analyzer.py

–û–±–Ω–æ–≤–∏—Ç–µ —Ñ–∞–π–ª `services/llm/analyzer.py`:

```python
from ollama import AsyncClient
from core.config import get_settings

settings = get_settings()

class LLMAnalyzer:
    def __init__(self):
        self.ollama_client = AsyncClient(host=settings.OLLAMA_BASE_URL)
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
        self.models = {
            'original': settings.OLLAMA_MODEL,  # ilyagusev/saiga_llama3
            'hashtag_enhanced': 'saiga-hashtag-pro'  # –í–∞—à–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        }
        
        # –§–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        self.use_enhanced_hashtag_model = True
    
    async def generate_hashtags(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ —Å –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–∏"""
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
        model_name = (
            self.models['hashtag_enhanced'] 
            if self.use_enhanced_hashtag_model 
            else self.models['original']
        )
        
        try:
            response = await self.ollama_client.generate(
                model=model_name,
                prompt=f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏: {text}",
                options={
                    "temperature": 0.1,
                    "top_p": 0.9,
                    "num_predict": 50
                }
            )
            
            hashtags = response['response'].strip()
            
            # –û—á–∏—Å—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            hashtags = self._clean_hashtags(hashtags)
            
            return hashtags
            
        except Exception as e:
            # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
            if self.use_enhanced_hashtag_model:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ enhanced –º–æ–¥–µ–ª–∏, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é: {e}")
                response = await self.ollama_client.generate(
                    model=self.models['original'],
                    prompt=f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏: {text}"
                )
                return self._clean_hashtags(response['response'])
            else:
                raise e
    
    def _clean_hashtags(self, hashtags: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ö–µ—à—Ç–µ–≥–∏"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        hashtags = hashtags.replace('#', '').strip()
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –∏ –æ—á–∏—â–∞–µ–º
        tags = [tag.strip() for tag in hashtags.split(',')]
        tags = [tag for tag in tags if tag and len(tag) > 2]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        tags = tags[:5]
        
        return ', '.join(tags)
    
    async def switch_model(self, use_enhanced: bool = True):
        """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏"""
        self.use_enhanced_hashtag_model = use_enhanced
        model_name = (
            self.models['hashtag_enhanced'] 
            if use_enhanced 
            else self.models['original']
        )
        print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –≤ –±–æ—Ç–∞

–í `bot/handlers.py` –¥–æ–±–∞–≤—å—Ç–µ –∫–æ–º–∞–Ω–¥—É:

```python
@dp.message(Command("switch_model"))
async def switch_model_command(message: types.Message):
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–µ—à—Ç–µ–≥–æ–≤"""
    
    args = message.text.split()
    if len(args) < 2:
        await message.reply(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /switch_model enhanced|original\n"
            "enhanced - –¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n"
            "original - –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å"
        )
        return
    
    model_type = args[1].lower()
    
    if model_type == "enhanced":
        await analyzer.switch_model(use_enhanced=True)
        await message.reply("‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å")
    elif model_type == "original":
        await analyzer.switch_model(use_enhanced=False)
        await message.reply("‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å")
    else:
        await message.reply("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: enhanced –∏–ª–∏ original")
```

---

## 5. üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
ollama list

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
ollama run saiga-hashtag-pro "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏
ollama show saiga-hashtag-pro
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ

–°–æ–∑–¥–∞–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç `test_enhanced_model.py`:

```python
import asyncio
from services.llm.analyzer import LLMAnalyzer

async def test_models():
    analyzer = LLMAnalyzer()
    
    test_text = "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –†–æ—Å—Å–∏–∏ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ 21% –≥–æ–¥–æ–≤—ã—Ö"
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    print(f"üì∞ –¢–µ–∫—Å—Ç: {test_text}")
    
    # –¢–µ—Å—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    await analyzer.switch_model(use_enhanced=False)
    original_hashtags = await analyzer.generate_hashtags(test_text)
    print(f"üîµ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è: {original_hashtags}")
    
    # –¢–µ—Å—Ç –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    await analyzer.switch_model(use_enhanced=True)
    enhanced_hashtags = await analyzer.generate_hashtags(test_text)
    print(f"üü¢ –î–æ–æ–±—É—á–µ–Ω–Ω–∞—è: {enhanced_hashtags}")

if __name__ == "__main__":
    asyncio.run(test_models())
```

–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç:

```bash
python test_enhanced_model.py
```

---

## 6. üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

–í `analyzer.py` –¥–æ–±–∞–≤—å—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:

```python
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class LLMAnalyzer:
    def __init__(self):
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
        self.model_usage_stats = {
            'original': 0,
            'enhanced': 0
        }
    
    async def generate_hashtags(self, text: str) -> str:
        model_type = 'enhanced' if self.use_enhanced_hashtag_model else 'original'
        self.model_usage_stats[model_type] += 1
        
        start_time = datetime.now()
        
        # ... –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à—Ç–µ–≥–æ–≤ ...
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info(f"Model: {model_type}, Duration: {duration:.2f}s, Text length: {len(text)}")
        
        return hashtags
    
    def get_usage_stats(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
        total = sum(self.model_usage_stats.values())
        if total == 0:
            return self.model_usage_stats
        
        return {
            'original': {
                'count': self.model_usage_stats['original'],
                'percentage': self.model_usage_stats['original'] / total * 100
            },
            'enhanced': {
                'count': self.model_usage_stats['enhanced'],
                'percentage': self.model_usage_stats['enhanced'] / total * 100
            },
            'total': total
        }
```

### –ö–æ–º–∞–Ω–¥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –±–æ—Ç–µ

```python
@dp.message(Command("model_stats"))
async def model_stats_command(message: types.Message):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    
    stats = analyzer.get_usage_stats()
    
    response = "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:\n\n"
    response += f"üîµ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è: {stats['original']['count']} ({stats['original']['percentage']:.1f}%)\n"
    response += f"üü¢ –î–æ–æ–±—É—á–µ–Ω–Ω–∞—è: {stats['enhanced']['count']} ({stats['enhanced']['percentage']:.1f}%)\n"
    response += f"üìà –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total']}"
    
    await message.reply(response)
```

---

## 7. üöÄ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import random

class LLMAnalyzer:
    def __init__(self):
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
        self.ab_test_enabled = False
        self.ab_test_ratio = 0.5  # 50% –Ω–∞ –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
    
    async def generate_hashtags_with_ab_test(self, text: str) -> dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ —Å A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        
        if not self.ab_test_enabled:
            hashtags = await self.generate_hashtags(text)
            return {
                'hashtags': hashtags,
                'model_used': 'enhanced' if self.use_enhanced_hashtag_model else 'original'
            }
        
        # A/B —Ç–µ—Å—Ç
        use_enhanced = random.random() < self.ab_test_ratio
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º –º–æ–¥–µ–ª—å
        original_setting = self.use_enhanced_hashtag_model
        self.use_enhanced_hashtag_model = use_enhanced
        
        hashtags = await self.generate_hashtags(text)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
        self.use_enhanced_hashtag_model = original_setting
        
        return {
            'hashtags': hashtags,
            'model_used': 'enhanced' if use_enhanced else 'original',
            'ab_test': True
        }
```

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É

```python
class LLMAnalyzer:
    def __init__(self):
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
        self.quality_threshold = 0.7
        self.auto_switch_enabled = False
    
    async def generate_hashtags_with_quality_check(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞"""
        
        if not self.auto_switch_enabled:
            return await self.generate_hashtags(text)
        
        # –ü—Ä–æ–±—É–µ–º –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        enhanced_hashtags = await self._generate_with_model(text, use_enhanced=True)
        quality_score = self._calculate_quality_score(text, enhanced_hashtags)
        
        if quality_score >= self.quality_threshold:
            return enhanced_hashtags
        else:
            # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é
            logger.warning(f"Low quality score: {quality_score}, switching to original model")
            return await self._generate_with_model(text, use_enhanced=False)
    
    def _calculate_quality_score(self, text: str, hashtags: str) -> float:
        """–ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ö–µ—à—Ç–µ–≥–æ–≤"""
        # –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —ç—Ç—É –ª–æ–≥–∏–∫—É
        
        tags = hashtags.split(',')
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if len(tags) < 2 or len(tags) > 6:
            return 0.3
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–ø—Ä–æ—Å—Ç–∞—è)
        text_lower = text.lower()
        relevant_count = 0
        
        for tag in tags:
            tag_clean = tag.strip().lower()
            if any(word in text_lower for word in tag_clean.split()):
                relevant_count += 1
        
        relevance_score = relevant_count / len(tags)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
        unique_words = set()
        for tag in tags:
            unique_words.update(tag.strip().lower().split())
        
        diversity_score = len(unique_words) / (len(tags) * 2)  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
        
        return (relevance_score + diversity_score) / 2
```

---

## 8. üéØ –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ö–µ–º–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Kaggle      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  –°–∫–∞—á–∏–≤–∞–Ω–∏–µ      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   –õ–æ–∫–∞–ª—å–Ω–∞—è     ‚îÇ
‚îÇ   (–û–±—É—á–µ–Ω–∏–µ)    ‚îÇ    ‚îÇ   –º–æ–¥–µ–ª–∏         ‚îÇ    ‚îÇ    –º–∞—à–∏–Ω–∞       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                         ‚îÇ
                                                         ‚ñº
                                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                               ‚îÇ     Ollama      ‚îÇ
                                               ‚îÇ (saiga-hashtag- ‚îÇ
                                               ‚îÇ      pro)       ‚îÇ
                                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                         ‚îÇ
                                                         ‚ñº
                                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                               ‚îÇ  –í–∞—à –ø—Ä–æ–µ–∫—Ç     ‚îÇ
                                               ‚îÇ  (analyzer.py)  ‚îÇ
                                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéâ –†–µ–∑—É–ª—å—Ç–∞—Ç

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —à–∞–≥–æ–≤ —É –≤–∞—Å –±—É–¥–µ—Ç:

‚úÖ **–î–æ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≤ Ollama** –ø–æ–¥ –∏–º–µ–Ω–µ–º `saiga-hashtag-pro`  
‚úÖ **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–µ–∫—Ç** —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è  
‚úÖ **–ö–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è** —á–µ—Ä–µ–∑ Telegram –±–æ—Ç–∞  
‚úÖ **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π  
‚úÖ **A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞  
‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ** –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–¢–µ–ø–µ—Ä—å –≤–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å, —Ç–∞–∫ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–µ—à—Ç–µ–≥–æ–≤! 