#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.
–í–∫–ª—é—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π, –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏, sentiment analysis –∏ –¥—Ä—É–≥–∏–µ —Ç–µ—Å—Ç—ã.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python evaluation/comprehensive_test.py --samples 50
    python evaluation/comprehensive_test.py --samples 100 --save-report
    python evaluation/comprehensive_test.py --channel durov --samples 30
"""

import argparse
import json
import sqlite3
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from collections import defaultdict, Counter
from dataclasses import dataclass
import numpy as np

import nltk
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

try:
    from transformers.pipelines import pipeline

    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# –°–∫–∞—á–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ NLTK
try:
    nltk.data.find("tokenizers/punkt")
except LookupError:
    print("–°–∫–∞—á–∏–≤–∞–µ–º NLTK punkt tokenizer...")
    nltk.download("punkt", quiet=True)

try:
    nltk.data.find("corpora/stopwords")
except LookupError:
    print("–°–∫–∞—á–∏–≤–∞–µ–º NLTK stopwords...")
    nltk.download("stopwords", quiet=True)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DEFAULT_NLI_MODEL = "cointegrated/rubert-base-cased-nli-threeway"
HALLUCINATION_THRESHOLDS = [0.3, 0.5, 0.7]


@dataclass
class HallucinationExample:
    """–ü—Ä–∏–º–µ—Ä –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""

    message_id: int
    channel: str
    original_text: str
    summary: str
    entailment_score: float
    is_hallucination: bool
    threshold: float
    analysis_type: str  # 'sentence' –∏–ª–∏ 'full_text'

    def to_dict(self) -> dict:
        return {
            "message_id": self.message_id,
            "channel": self.channel,
            "original_text": (
                self.original_text[:200] + "..."
                if len(self.original_text) > 200
                else self.original_text
            ),
            "summary": self.summary,
            "entailment_score": float(self.entailment_score),
            "is_hallucination": self.is_hallucination,
            "threshold": self.threshold,
            "analysis_type": self.analysis_type,
        }


class NewsAnalysisEvaluator:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π."""

    def __init__(self, db_path: Path = Path("data/storage.db")):
        self.db_path = db_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        print(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è evaluator...")
        print(f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"üóÑÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db_path}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å NLI –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        self.nli_tokenizer = None
        self.nli_model = None
        self._load_nli_model()

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
        self.test_results = {
            "timestamp": datetime.now().isoformat(),
            "device": str(self.device),
            "database_path": str(self.db_path),
            "tests": {},
        }

    def _load_nli_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç NLI –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π."""
        try:
            print(f"ü§ñ –ó–∞–≥—Ä—É–∂–∞–µ–º NLI –º–æ–¥–µ–ª—å: {DEFAULT_NLI_MODEL}")
            self.nli_tokenizer = AutoTokenizer.from_pretrained(DEFAULT_NLI_MODEL)
            self.nli_model = AutoModelForSequenceClassification.from_pretrained(
                DEFAULT_NLI_MODEL
            )
            self.nli_model.to(self.device)
            self.nli_model.eval()
            print("‚úÖ NLI –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ NLI –º–æ–¥–µ–ª–∏: {e}")
            print("‚ö†Ô∏è –¢–µ—Å—Ç—ã –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã")

    def fetch_test_data(
        self, limit: int = 100, channel_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        if not self.db_path.exists():
            print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.db_path}")
            return []

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row

            query = """
            SELECT 
                m.message_id,
                m.text,
                m.channel_id,
                m.channel_title,
                m.channel_username,
                m.date,
                a.summary,
                a.sentiment,
                a.hashtags
            FROM messages m
            JOIN analyses a ON m.message_id = a.message_id
            WHERE m.text IS NOT NULL 
            AND a.summary IS NOT NULL
            AND LENGTH(m.text) > 50
            AND LENGTH(a.summary) > 10
            """

            params = []
            if channel_filter:
                query += " AND m.channel_id = ?"
                params.append(channel_filter)

            query += " ORDER BY RANDOM() LIMIT ?"
            params.append(limit)

            cursor = conn.execute(query, params)
            rows = cursor.fetchall()
            conn.close()

            data = [dict(row) for row in rows]
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return data

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []

    def test_database_integrity(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        print("\nüîç –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")

        if not self.db_path.exists():
            return {"status": "failed", "error": "Database file not found"}

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü
            tables_info = {}
            for table in ["messages", "analyses", "subscribers", "channels"]:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                tables_info[table] = count
                print(f"  üìã {table}: {count} –∑–∞–ø–∏—Å–µ–π")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            cursor.execute(
                """
                SELECT COUNT(*) FROM messages m 
                JOIN analyses a ON m.message_id = a.message_id
            """
            )
            linked_count = cursor.fetchone()[0]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            cursor.execute(
                """
                SELECT 
                    COUNT(*) as total,
                    SUM(CASE WHEN LENGTH(text) < 10 THEN 1 ELSE 0 END) as short_texts,
                    SUM(CASE WHEN LENGTH(summary) < 5 THEN 1 ELSE 0 END) as short_summaries,
                    SUM(CASE WHEN sentiment IS NULL THEN 1 ELSE 0 END) as missing_sentiment
                FROM messages m 
                JOIN analyses a ON m.message_id = a.message_id
            """
            )
            quality_stats = cursor.fetchone()

            conn.close()

            result = {
                "status": "passed",
                "tables_info": tables_info,
                "linked_records": linked_count,
                "data_quality": {
                    "total_records": quality_stats[0],
                    "short_texts": quality_stats[1],
                    "short_summaries": quality_stats[2],
                    "missing_sentiment": quality_stats[3],
                },
            }

            print(f"  ‚úÖ –°–≤—è–∑–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {linked_count}")
            print(
                f"  üìä –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {quality_stats[1]} –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤, {quality_stats[2]} –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–∞–º–º–∞—Ä–∏"
            )

            return result

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    def test_hallucination_detection(
        self, data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π —Å –¥–≤—É–º—è –ø–æ–¥—Ö–æ–¥–∞–º–∏."""
        print(f"\nüîç –¢–µ—Å—Ç 2: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        if not self.nli_model:
            return {"status": "skipped", "reason": "NLI model not available"}

        start_time = time.time()

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–≤—É—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        sentence_results = []
        fulltext_results = []
        hallucination_examples = []

        for i, item in enumerate(data):
            if i % 20 == 0 and i > 0:
                print(f"  üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤...")

            premise = item["text"]
            summary = item["summary"]
            message_id = item["message_id"]
            channel = item["channel_id"]

            # 1. SENTENCE-LEVEL –ê–ù–ê–õ–ò–ó (–∫–∞–∫ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ)
            sentences = self._split_sentences(summary)
            sentence_scores = []

            for sentence in sentences:
                if len(sentence.strip()) > 5:
                    score = self._get_entailment_score(premise, sentence.strip())
                    sentence_scores.append(score)

            if sentence_scores:
                sentence_result = {
                    "message_id": message_id,
                    "channel": channel,
                    "text_length": len(premise.split()),
                    "summary_length": len(summary.split()),
                    "sentences_count": len(sentence_scores),
                    "avg_entailment": np.mean(sentence_scores),
                    "min_entailment": np.min(sentence_scores),
                    "max_entailment": np.max(sentence_scores),
                }

                # –í—ã—á–∏—Å–ª—è–µ–º hallucination rates –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤ (sentence-level)
                for threshold in HALLUCINATION_THRESHOLDS:
                    hallucinated = sum(
                        1 for score in sentence_scores if score < threshold
                    )
                    sentence_result[f"hallucination_rate_{threshold}"] = (
                        hallucinated / len(sentence_scores)
                    )

                sentence_results.append(sentence_result)

            # 2. FULL-TEXT –ê–ù–ê–õ–ò–ó (–Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥)
            fulltext_score = self._get_entailment_score(premise[:512], summary[:256])

            fulltext_result = {
                "message_id": message_id,
                "channel": channel,
                "text_length": len(premise.split()),
                "summary_length": len(summary.split()),
                "entailment_score": fulltext_score,
            }

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞ (full-text)
            for threshold in HALLUCINATION_THRESHOLDS:
                is_hallucination = fulltext_score < threshold
                fulltext_result[f"is_hallucination_{threshold}"] = is_hallucination

                # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                if (
                    is_hallucination and len(hallucination_examples) < 15
                ):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
                    example = HallucinationExample(
                        message_id=message_id,
                        channel=channel,
                        original_text=premise,
                        summary=summary,
                        entailment_score=fulltext_score,
                        is_hallucination=is_hallucination,
                        threshold=threshold,
                        analysis_type="full_text",
                    )
                    hallucination_examples.append(example)

            fulltext_results.append(fulltext_result)

        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è sentence-level
        sentence_stats = {}
        if sentence_results:
            sentence_stats = self._compute_hallucination_stats(sentence_results)
            sentence_stats["analysis_type"] = "sentence_level"

        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è full-text
        fulltext_stats = {}
        if fulltext_results:
            fulltext_stats = {
                "analysis_type": "full_text",
                "samples_count": len(fulltext_results),
                "avg_entailment": np.mean(
                    [r["entailment_score"] for r in fulltext_results]
                ),
                "std_entailment": np.std(
                    [r["entailment_score"] for r in fulltext_results]
                ),
                "min_entailment": np.min(
                    [r["entailment_score"] for r in fulltext_results]
                ),
                "max_entailment": np.max(
                    [r["entailment_score"] for r in fulltext_results]
                ),
            }

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ—Ä–æ–≥–∞–º –¥–ª—è full-text
            for threshold in HALLUCINATION_THRESHOLDS:
                hallucinations = [
                    r for r in fulltext_results if r[f"is_hallucination_{threshold}"]
                ]
                fulltext_stats[f"hallucination_count_{threshold}"] = len(hallucinations)
                fulltext_stats[f"hallucination_rate_{threshold}"] = len(
                    hallucinations
                ) / len(fulltext_results)

        execution_time = time.time() - start_time

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"  ‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.1f}—Å")

        if sentence_stats:
            print(f"  üìù SENTENCE-LEVEL –∞–Ω–∞–ª–∏–∑:")
            print(
                f"    üéØ –°—Ä–µ–¥–Ω–∏–π entailment score: {sentence_stats['avg_entailment']:.3f}"
            )
            for threshold in HALLUCINATION_THRESHOLDS:
                rate = sentence_stats[f"avg_hallucination_rate_{threshold}"]
                print(f"    üö® –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ (–ø–æ—Ä–æ–≥ {threshold}): {rate:.1%}")

        if fulltext_stats:
            print(f"  üìÑ FULL-TEXT –∞–Ω–∞–ª–∏–∑:")
            print(
                f"    üéØ –°—Ä–µ–¥–Ω–∏–π entailment score: {fulltext_stats['avg_entailment']:.3f}"
            )
            for threshold in HALLUCINATION_THRESHOLDS:
                rate = fulltext_stats[f"hallucination_rate_{threshold}"]
                print(f"    üö® –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ (–ø–æ—Ä–æ–≥ {threshold}): {rate:.1%}")

        if hallucination_examples:
            print(f"  üìã –ù–∞–π–¥–µ–Ω–æ {len(hallucination_examples)} –ø—Ä–∏–º–µ—Ä–æ–≤ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π")

        return {
            "status": "passed",
            "execution_time": execution_time,
            "samples_processed": len(data),
            "sentence_level_analysis": {
                "statistics": sentence_stats,
                "detailed_results": sentence_results[:5],  # –ü–µ—Ä–≤—ã–µ 5 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
            },
            "full_text_analysis": {
                "statistics": fulltext_stats,
                "detailed_results": fulltext_results[:5],  # –ü–µ—Ä–≤—ã–µ 5 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
            },
            "hallucination_examples": [
                ex.to_dict() for ex in hallucination_examples[:10]
            ],  # –¢–æ–ø-10 –ø—Ä–∏–º–µ—Ä–æ–≤
        }

    def test_sentiment_consistency(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–¢–µ—Å—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ sentiment analysis."""
        print(f"\nüîç –¢–µ—Å—Ç 3: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å sentiment analysis ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        sentiment_distribution = Counter()
        sentiment_by_channel = defaultdict(Counter)
        text_length_by_sentiment = defaultdict(list)

        for item in data:
            sentiment = item.get("sentiment", "Unknown")
            channel = item.get("channel_id", "Unknown")
            text_length = len(item.get("text", "").split())

            sentiment_distribution[sentiment] += 1
            sentiment_by_channel[channel][sentiment] += 1
            text_length_by_sentiment[sentiment].append(text_length)

        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        total_samples = len(data)
        sentiment_stats = {}

        for sentiment, count in sentiment_distribution.items():
            percentage = (count / total_samples) * 100
            avg_text_length = (
                np.mean(text_length_by_sentiment[sentiment])
                if text_length_by_sentiment[sentiment]
                else 0
            )

            sentiment_stats[sentiment] = {
                "count": count,
                "percentage": percentage,
                "avg_text_length": avg_text_length,
            }

            print(
                f"  üìä {sentiment}: {count} ({percentage:.1f}%), —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {avg_text_length:.0f} —Å–ª–æ–≤"
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏
        anomalies = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ –∫–∞–Ω–∞–ª–æ–≤ —Å –æ—á–µ–Ω—å —Å—Ç—Ä–∞–Ω–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        for channel, channel_sentiments in sentiment_by_channel.items():
            if sum(channel_sentiments.values()) >= 5:  # –ú–∏–Ω–∏–º—É–º 5 –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                positive_ratio = channel_sentiments.get("–ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è", 0) / sum(
                    channel_sentiments.values()
                )
                negative_ratio = channel_sentiments.get("–ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è", 0) / sum(
                    channel_sentiments.values()
                )

                if positive_ratio > 0.8:
                    anomalies.append(
                        f"–ö–∞–Ω–∞–ª {channel}: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π ({positive_ratio:.1%})"
                    )
                elif negative_ratio > 0.8:
                    anomalies.append(
                        f"–ö–∞–Ω–∞–ª {channel}: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π ({negative_ratio:.1%})"
                    )

        result = {
            "status": "passed",
            "total_samples": total_samples,
            "sentiment_distribution": dict(sentiment_distribution),
            "sentiment_statistics": sentiment_stats,
            "channels_analyzed": len(sentiment_by_channel),
            "anomalies": anomalies,
        }

        if anomalies:
            print(f"  ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {len(anomalies)}")
            for anomaly in anomalies[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"    ‚Ä¢ {anomaly}")
        else:
            print("  ‚úÖ –ê–Ω–æ–º–∞–ª–∏–π –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

        return result

    def test_summarization_quality(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏."""
        print(f"\nüîç –¢–µ—Å—Ç 4: –ö–∞—á–µ—Å—Ç–≤–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        compression_ratios = []
        word_overlaps = []
        summary_lengths = []

        for item in data:
            original_text = item["text"]
            summary = item["summary"]

            # –ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω—ã
            orig_words = len(original_text.split())
            summ_words = len(summary.split())

            if orig_words > 0:
                compression_ratio = 1 - (summ_words / orig_words)
                compression_ratios.append(compression_ratio)
                summary_lengths.append(summ_words)

                # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å–ª–æ–≤ (extractiveness)
                orig_words_set = set(original_text.lower().split())
                summ_words_set = set(summary.lower().split())

                if summ_words_set:
                    word_overlap = len(orig_words_set & summ_words_set) / len(
                        summ_words_set
                    )
                    word_overlaps.append(word_overlap)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            "avg_compression_ratio": (
                np.mean(compression_ratios) if compression_ratios else 0
            ),
            "std_compression_ratio": (
                np.std(compression_ratios) if compression_ratios else 0
            ),
            "avg_summary_length": np.mean(summary_lengths) if summary_lengths else 0,
            "avg_word_overlap": np.mean(word_overlaps) if word_overlaps else 0,
            "samples_analyzed": len(compression_ratios),
        }

        print(f"  üìè –°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: {stats['avg_compression_ratio']:.1%}")
        print(f"  üìù –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–∞–º–º–∞—Ä–∏: {stats['avg_summary_length']:.0f} —Å–ª–æ–≤")
        print(f"  üîó –°—Ä–µ–¥–Ω–µ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤: {stats['avg_word_overlap']:.1%}")

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_issues = []

        if stats["avg_compression_ratio"] < 0.3:
            quality_issues.append("–ù–∏–∑–∫–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è - —Å–∞–º–º–∞—Ä–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ")
        elif stats["avg_compression_ratio"] > 0.9:
            quality_issues.append(
                "–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è - —Å–∞–º–º–∞—Ä–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–º–∏"
            )

        if stats["avg_word_overlap"] < 0.3:
            quality_issues.append(
                "–ù–∏–∑–∫–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–æ –º–Ω–æ–≥–æ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π"
            )
        elif stats["avg_word_overlap"] > 0.8:
            quality_issues.append(
                "–í—ã—Å–æ–∫–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤ - —Å–∞–º–º–∞—Ä–∏ —Å–ª–∏—à–∫–æ–º extractive"
            )

        result = {
            "status": "passed",
            "statistics": stats,
            "quality_issues": quality_issues,
        }

        if quality_issues:
            print(f"  ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º –∫–∞—á–µ—Å—Ç–≤–∞: {len(quality_issues)}")
            for issue in quality_issues:
                print(f"    ‚Ä¢ {issue}")
        else:
            print("  ‚úÖ –°–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º —Å –∫–∞—á–µ—Å—Ç–≤–æ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

        return result

    def test_hashtag_relevance(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–¢–µ—Å—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ö–µ—à—Ç–µ–≥–æ–≤."""
        print(f"\nüîç –¢–µ—Å—Ç 5: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ö–µ—à—Ç–µ–≥–æ–≤ ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        hashtag_counter = Counter()
        hashtags_per_message = []

        for item in data:
            hashtags_str = item.get("hashtags", "")
            if hashtags_str:
                try:
                    # –ü–∞—Ä—Å–∏–º JSON –∏–ª–∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º
                    if hashtags_str.startswith("["):
                        hashtags = json.loads(hashtags_str)
                    else:
                        hashtags = [tag.strip() for tag in hashtags_str.split(",")]

                    hashtags_per_message.append(len(hashtags))
                    for tag in hashtags:
                        if tag:
                            hashtag_counter[tag.lower().replace("#", "")] += 1
                except:
                    hashtags_per_message.append(0)
            else:
                hashtags_per_message.append(0)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        most_common_hashtags = hashtag_counter.most_common(10)
        avg_hashtags_per_message = (
            np.mean(hashtags_per_message) if hashtags_per_message else 0
        )

        print(
            f"  üè∑Ô∏è –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö–µ—à—Ç–µ–≥–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ: {avg_hashtags_per_message:.1f}"
        )
        print(f"  üìä –¢–æ–ø-5 —Ö–µ—à—Ç–µ–≥–æ–≤:")

        for i, (tag, count) in enumerate(most_common_hashtags[:5], 1):
            percentage = (count / len(data)) * 100
            print(f"    {i}. #{tag}: {count} ({percentage:.1f}%)")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_issues = []

        if avg_hashtags_per_message < 1:
            quality_issues.append("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ö–µ—à—Ç–µ–≥–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ")
        elif avg_hashtags_per_message > 7:
            quality_issues.append("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ö–µ—à—Ç–µ–≥–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
        unique_hashtags = len(hashtag_counter)
        if unique_hashtags < 10:
            quality_issues.append("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ö–µ—à—Ç–µ–≥–æ–≤")

        result = {
            "status": "passed",
            "avg_hashtags_per_message": avg_hashtags_per_message,
            "unique_hashtags_count": unique_hashtags,
            "most_common_hashtags": most_common_hashtags,
            "quality_issues": quality_issues,
        }

        if quality_issues:
            print(f"  ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã —Å —Ö–µ—à—Ç–µ–≥–∞–º–∏: {len(quality_issues)}")
            for issue in quality_issues:
                print(f"    ‚Ä¢ {issue}")
        else:
            print("  ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ —Ö–µ—à—Ç–µ–≥–æ–≤ –≤ –Ω–æ—Ä–º–µ")

        return result

    def _split_sentences(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        try:
            sentences = nltk.sent_tokenize(text, language="russian")
        except:
            import re

            sentences = re.split(r"[.!?]+\s+", text)
            sentences = [s.strip() for s in sentences if s.strip()]

        return [s for s in sentences if len(s.split()) >= 3]

    def _get_entailment_score(self, premise: str, hypothesis: str) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ entailment score —Å –ø–æ–º–æ—â—å—é NLI –º–æ–¥–µ–ª–∏."""
        if not self.nli_tokenizer or not self.nli_model:
            return 0.0

        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞
            premise = premise[:512]
            hypothesis = hypothesis[:256]

            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = self.nli_tokenizer.encode_plus(
                premise,
                hypothesis,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512,
            )

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.nli_model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)

                # –ò–Ω–¥–µ–∫—Å –¥–ª—è entailment (–æ–±—ã—á–Ω–æ 0 –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏)
                entailment_score = predictions[0][0].item()

            return entailment_score

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è entailment score: {e}")
            return 0.0

    def _compute_hallucination_stats(self, results: List[Dict]) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º."""
        stats = {
            "samples_count": len(results),
            "avg_entailment": np.mean([r["avg_entailment"] for r in results]),
            "std_entailment": np.std([r["avg_entailment"] for r in results]),
            "avg_text_length": np.mean([r["text_length"] for r in results]),
            "avg_summary_length": np.mean([r["summary_length"] for r in results]),
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ—Ä–æ–≥–∞–º
        for threshold in HALLUCINATION_THRESHOLDS:
            rates = [r[f"hallucination_rate_{threshold}"] for r in results]
            stats[f"avg_hallucination_rate_{threshold}"] = np.mean(rates)
            stats[f"median_hallucination_rate_{threshold}"] = np.median(rates)
            stats[f"std_hallucination_rate_{threshold}"] = np.std(rates)

        return stats

    def run_all_tests(
        self, samples: int = 100, channel_filter: Optional[str] = None
    ) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã."""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {samples}")
        if channel_filter:
            print(f"üì∫ –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω–∞–ª—É: {channel_filter}")
        print("=" * 60)

        start_time = time.time()

        # –¢–µ—Å—Ç 1: –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        self.test_results["tests"][
            "database_integrity"
        ] = self.test_database_integrity()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
        test_data = self.fetch_test_data(samples, channel_filter)

        if not test_data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return self.test_results

        # –¢–µ—Å—Ç 2: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        self.test_results["tests"]["hallucination_detection"] = (
            self.test_hallucination_detection(test_data)
        )

        # –¢–µ—Å—Ç 3: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å sentiment analysis
        self.test_results["tests"]["sentiment_consistency"] = (
            self.test_sentiment_consistency(test_data)
        )

        # –¢–µ—Å—Ç 4: –ö–∞—á–µ—Å—Ç–≤–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        self.test_results["tests"]["summarization_quality"] = (
            self.test_summarization_quality(test_data)
        )

        # –¢–µ—Å—Ç 5: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ö–µ—à—Ç–µ–≥–æ–≤
        self.test_results["tests"]["hashtag_relevance"] = self.test_hashtag_relevance(
            test_data
        )

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = time.time() - start_time
        self.test_results["execution_summary"] = {
            "total_execution_time": total_time,
            "samples_tested": len(test_data),
            "tests_run": len(self.test_results["tests"]),
            "tests_passed": sum(
                1
                for test in self.test_results["tests"].values()
                if test.get("status") == "passed"
            ),
            "tests_failed": sum(
                1
                for test in self.test_results["tests"].values()
                if test.get("status") == "failed"
            ),
            "tests_skipped": sum(
                1
                for test in self.test_results["tests"].values()
                if test.get("status") == "skipped"
            ),
        }

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
        print("\n" + "=" * 60)
        print("üìã –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
        summary = self.test_results["execution_summary"]
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {summary['total_execution_time']:.1f}—Å")
        print(f"üìä –û–±—Ä–∞–∑—Ü–æ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {summary['samples_tested']}")
        print(f"‚úÖ –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ: {summary['tests_passed']}")
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ: {summary['tests_failed']}")
        print(f"‚è≠Ô∏è –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {summary['tests_skipped']}")

        return self.test_results

    def save_report(self, output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏."""
        # JSON –æ—Ç—á–µ—Ç
        json_path = output_path.with_suffix(".json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)

        # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        txt_path = output_path.with_suffix(".txt")
        with open(txt_path, "w", encoding="utf-8") as f:
            self._write_text_report(f)

        print(f"\nüíæ –û—Ç—á–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"  üìÑ JSON: {json_path}")
        print(f"  üìù TXT: {txt_path}")

    def _write_text_report(self, f):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
        f.write("üîç –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –û–¢–ß–ï–¢ –ü–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ –°–ò–°–¢–ï–ú–´ –ê–ù–ê–õ–ò–ó–ê –ù–û–í–û–°–¢–ï–ô\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"üìÖ –î–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {self.test_results['timestamp']}\n")
        f.write(f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.test_results['device']}\n")
        f.write(f"üóÑÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.test_results['database_path']}\n\n")

        # –ò—Ç–æ–≥–∏
        if "execution_summary" in self.test_results:
            summary = self.test_results["execution_summary"]
            f.write("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:\n")
            f.write("-" * 30 + "\n")
            f.write(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {summary['total_execution_time']:.1f}—Å\n")
            f.write(f"üìù –û–±—Ä–∞–∑—Ü–æ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {summary['samples_tested']}\n")
            f.write(f"‚úÖ –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ: {summary['tests_passed']}\n")
            f.write(f"‚ùå –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ: {summary['tests_failed']}\n")
            f.write(f"‚è≠Ô∏è –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {summary['tests_skipped']}\n\n")

        # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–µ—Å—Ç—É
        for test_name, test_result in self.test_results.get("tests", {}).items():
            f.write(f"üîç –¢–ï–°–¢: {test_name.upper()}\n")
            f.write("-" * 40 + "\n")
            f.write(f"–°—Ç–∞—Ç—É—Å: {test_result.get('status', 'unknown')}\n")

            if test_result.get("status") == "failed":
                f.write(f"–û—à–∏–±–∫–∞: {test_result.get('error', 'Unknown error')}\n")
            elif test_result.get("status") == "skipped":
                f.write(
                    f"–ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∞: {test_result.get('reason', 'Unknown reason')}\n"
                )

            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
            if (
                test_name == "hallucination_detection"
                and test_result.get("status") == "passed"
            ):
                f.write("üìù SENTENCE-LEVEL –ê–ù–ê–õ–ò–ó:\n")
                if (
                    "sentence_level_analysis" in test_result
                    and "statistics" in test_result["sentence_level_analysis"]
                ):
                    stats = test_result["sentence_level_analysis"]["statistics"]
                    f.write(
                        f"  –°—Ä–µ–¥–Ω–∏–π entailment score: {stats.get('avg_entailment', 0):.3f}\n"
                    )
                    for threshold in HALLUCINATION_THRESHOLDS:
                        rate = stats.get(f"avg_hallucination_rate_{threshold}", 0)
                        f.write(f"  –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ (–ø–æ—Ä–æ–≥ {threshold}): {rate:.1%}\n")

                f.write("\nüìÑ FULL-TEXT –ê–ù–ê–õ–ò–ó:\n")
                if (
                    "full_text_analysis" in test_result
                    and "statistics" in test_result["full_text_analysis"]
                ):
                    stats = test_result["full_text_analysis"]["statistics"]
                    f.write(
                        f"  –°—Ä–µ–¥–Ω–∏–π entailment score: {stats.get('avg_entailment', 0):.3f}\n"
                    )
                    f.write(
                        f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {stats.get('std_entailment', 0):.3f}\n"
                    )
                    for threshold in HALLUCINATION_THRESHOLDS:
                        rate = stats.get(f"hallucination_rate_{threshold}", 0)
                        count = stats.get(f"hallucination_count_{threshold}", 0)
                        f.write(
                            f"  –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ (–ø–æ—Ä–æ–≥ {threshold}): {rate:.1%} ({count} –∏–∑ {stats.get('samples_count', 0)})\n"
                        )

                # –ü—Ä–∏–º–µ—Ä—ã –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
                if (
                    "hallucination_examples" in test_result
                    and test_result["hallucination_examples"]
                ):
                    f.write(
                        f"\nüìã –ü–†–ò–ú–ï–†–´ –ì–ê–õ–õ–Æ–¶–ò–ù–ê–¶–ò–ô ({len(test_result['hallucination_examples'])}):\n"
                    )
                    for i, example in enumerate(
                        test_result["hallucination_examples"][:3], 1
                    ):
                        f.write(f"  –ü—Ä–∏–º–µ—Ä {i}:\n")
                        f.write(
                            f"    ID: {example['message_id']}, –ö–∞–Ω–∞–ª: {example['channel']}\n"
                        )
                        f.write(
                            f"    Entailment score: {example['entailment_score']:.3f}\n"
                        )
                        f.write(f"    –ü–æ—Ä–æ–≥: {example['threshold']}\n")
                        f.write(f"    –û—Ä–∏–≥–∏–Ω–∞–ª: {example['original_text'][:100]}...\n")
                        f.write(f"    –°–∞–º–º–∞—Ä–∏: {example['summary']}\n\n")

            # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–µ—Å—Ç–æ–≤
            elif "statistics" in test_result:
                f.write("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n")
                for key, value in test_result["statistics"].items():
                    if isinstance(value, float):
                        f.write(f"  {key}: {value:.3f}\n")
                    else:
                        f.write(f"  {key}: {value}\n")

            f.write("\n")


def main():
    parser = argparse.ArgumentParser(
        description="–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python evaluation/comprehensive_test.py --samples 50
  python evaluation/comprehensive_test.py --samples 100 --save-report
  python evaluation/comprehensive_test.py --channel durov --samples 30 --save-report
        """,
    )

    parser.add_argument(
        "--samples",
        type=int,
        default=50,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 50)",
    )

    parser.add_argument(
        "--channel", type=str, default=None, help="–§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∫–∞–Ω–∞–ª—É"
    )

    parser.add_argument(
        "--db",
        type=Path,
        default=Path("data/storage.db"),
        help="–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: data/storage.db)",
    )

    parser.add_argument(
        "--save-report", action="store_true", help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª—ã"
    )

    parser.add_argument(
        "--output",
        type=Path,
        default=Path("evaluation/test_report"),
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)",
    )

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º evaluator –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    evaluator = NewsAnalysisEvaluator(args.db)
    results = evaluator.run_all_tests(samples=args.samples, channel_filter=args.channel)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if args.save_report:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        evaluator.save_report(args.output)

    print(f"\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    main()
