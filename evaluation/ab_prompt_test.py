#!/usr/bin/env python3
"""
A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM.
"""

import argparse
import asyncio
import sqlite3
import json
import random
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime
from dataclasses import dataclass
import numpy as np

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
import sys

sys.path.append(".")

try:
    from services.llm import OllamaAnalyzer

    SYSTEM_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã: {e}")
    SYSTEM_AVAILABLE = False


@dataclass
class PromptVariant:
    """–í–∞—Ä–∏–∞–Ω—Ç –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""

    name: str
    system_prompt: str
    user_prompt_template: str
    temperature: float = 0.7
    max_tokens: int = 1000
    description: str = ""


class ABPromptTester:
    """A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π."""

    def __init__(self, db_path: Path = Path("data/storage.db")):
        self.db_path = db_path
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "test_variants": {},
            "comparisons": {},
            "summary": {},
        }

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if SYSTEM_AVAILABLE:
            try:
                self.analyzer = OllamaAnalyzer()
                print("‚úÖ LLM –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: {e}")
                self.analyzer = None
        else:
            self.analyzer = None

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.prompt_variants = self._define_prompt_variants()

    def _define_prompt_variants(self) -> List[PromptVariant]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""

        variants = [
            # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –≥—Ä—É–ø–ø–∞)
            PromptVariant(
                name="original",
                system_prompt="""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –Ω–æ–≤–æ—Å—Ç–µ–π. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑.""",
                user_prompt_template="""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç:

{text}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∞–Ω–∞–ª–∏–∑ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:
- –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
- –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è)
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã (–¥–æ 5 —Ç–µ–º)
- –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–¥–æ 10 —Å–ª–æ–≤)
- –•–µ—à—Ç–µ–≥–∏ (–¥–æ 5 —Ö–µ—à—Ç–µ–≥–æ–≤)""",
                temperature=0.7,
                description="–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–∏—Å—Ç–µ–º—ã",
            ),
            # –ë–æ–ª–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            PromptVariant(
                name="structured",
                system_prompt="""–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≤ –º–µ–¥–∏–∞-–∏–Ω–¥—É—Å—Ç—Ä–∏–∏. 
–¢–≤–æ—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è - –±—ã—Å—Ç—Ä—ã–π –∏ —Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤.""",
                user_prompt_template="""–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç

–¢–ï–ö–°–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{text}

–¢–†–ï–ë–£–ï–ú–´–ô –ê–ù–ê–õ–ò–ó:

1. –†–ï–ó–Æ–ú–ï: –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –≤ 2-3 —á–µ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
2. –¢–û–ù–ê–õ–¨–ù–û–°–¢–¨: –û–ø—Ä–µ–¥–µ–ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É (–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è)
3. –ö–ê–¢–ï–ì–û–†–ò–Ø: –û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—É—é —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
4. –ö–õ–Æ–ß–ï–í–´–ï –¢–ï–ú–´: –í—ã–¥–µ–ª–∏ 3-5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º
5. –í–ê–ñ–ù–´–ï –¢–ï–†–ú–ò–ù–´: –ù–∞–π–¥–∏ 5-8 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤/—Ç–µ—Ä–º–∏–Ω–æ–≤
6. –•–ï–®–¢–ï–ì–ò: –ü—Ä–µ–¥–ª–æ–∂–∏ 3-5 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ö–µ—à—Ç–µ–≥–æ–≤""",
                temperature=0.5,
                description="–ë–æ–ª–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç",
            ),
            # –ü—Ä–æ–º–ø—Ç —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ
            PromptVariant(
                name="quality_focused",
                system_prompt="""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –Ω–æ–≤–æ—Å—Ç–µ–π —Å –≤—ã—Å–æ–∫–∏–º–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –∏–∑–±–µ–≥–∞—è –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –∏ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤.""",
                user_prompt_template="""–ü—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:

{text}

–í–∞–∂–Ω–æ:
- –†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º
- –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª—è–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –¢–µ–º—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏, –Ω–µ –æ–±—â–∏–º–∏
- –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ - —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è
- –•–µ—à—Ç–µ–≥–∏ - –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–µ –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
–†–µ–∑—é–º–µ: [2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]
–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: [–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è + –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ]
–¢–µ–º—ã: [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ–º—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é]
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: [–≤–∞–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é]
–•–µ—à—Ç–µ–≥–∏: [#—Ö–µ—à—Ç–µ–≥1 #—Ö–µ—à—Ç–µ–≥2 #—Ö–µ—à—Ç–µ–≥3]""",
                temperature=0.3,
                description="–ü—Ä–æ–º–ø—Ç —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å",
            ),
            # –ö—Ä–∞—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç
            PromptVariant(
                name="concise",
                system_prompt="""–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –∫—Ä–∞—Ç–∫–∏–π, –Ω–æ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑.""",
                user_prompt_template="""–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏:
{text}

–ù—É–∂–Ω–æ:
–†–µ–∑—é–º–µ (–∫—Ä–∞—Ç–∫–æ), –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –¢–µ–º—ã, –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –•–µ—à—Ç–µ–≥–∏""",
                temperature=0.7,
                description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç",
            ),
            # –ü—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
            PromptVariant(
                name="with_examples",
                system_prompt="""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –Ω–æ–≤–æ—Å—Ç–µ–π. –ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ –æ–±—Ä–∞–∑–µ—Ü –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.""",
                user_prompt_template="""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑—Ü—É:

–ü–†–ò–ú–ï–† –ê–ù–ê–õ–ò–ó–ê:
–†–µ–∑—é–º–µ: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ 15% –¥–ª—è –±–æ—Ä—å–±—ã —Å –∏–Ω—Ñ–ª—è—Ü–∏–µ–π. –†–µ—à–µ–Ω–∏–µ –≤—ã–∑–≤–∞–ª–æ —Å–º–µ—à–∞–Ω–Ω—É—é —Ä–µ–∞–∫—Ü–∏—é —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.
–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–Ω–µ–Ω–∏—è–º–∏)
–¢–µ–º—ã: –¥–µ–Ω–µ–∂–Ω–æ-–∫—Ä–µ–¥–∏—Ç–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞, –∏–Ω—Ñ–ª—è—Ü–∏—è, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: –¶–ë, –∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞, –∏–Ω—Ñ–ª—è—Ü–∏—è, –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è —Å—Ç–∞–≤–∫–∞
–•–µ—à—Ç–µ–≥–∏: #–¶–ë #—Å—Ç–∞–≤–∫–∞ #–∏–Ω—Ñ–ª—è—Ü–∏—è #—ç–∫–æ–Ω–æ–º–∏–∫–∞

–¢–í–û–Ø –ó–ê–î–ê–ß–ê - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç:
{text}

–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç –∏ –ø–æ–¥—Ö–æ–¥.""",
                temperature=0.6,
                description="–ü—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–æ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
            ),
        ]

        return variants

    def _get_test_texts(self, limit: int = 50) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        if not self.db_path.exists():
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
            return [
                {
                    "message_id": f"test_{i}",
                    "text": f"–¢–µ—Å—Ç–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å –Ω–æ–º–µ—Ä {i} –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞. "
                    * 10,
                    "channel_id": "test_channel",
                }
                for i in range(limit)
            ]

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row

            cursor = conn.execute(
                """
                SELECT message_id, text, channel_id
                FROM messages 
                WHERE LENGTH(text) > 200 AND LENGTH(text) < 2000
                AND text NOT LIKE '%@%'  -- –ò—Å–∫–ª—é—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏
                ORDER BY RANDOM() LIMIT ?
            """,
                (limit,),
            )

            texts = []
            for row in cursor.fetchall():
                texts.append(
                    {
                        "message_id": row["message_id"],
                        "text": row["text"],
                        "channel_id": row["channel_id"],
                    }
                )

            conn.close()
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(texts)} —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤")
            return texts

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []

    async def _analyze_with_variant(
        self, text: str, variant: PromptVariant
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞."""
        if not self.analyzer:
            return {"error": "Analyzer not available"}

        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞
            # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É OllamaAnalyzer

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            user_prompt = variant.user_prompt_template.format(text=text)

            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ (—ç—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å)
            result = await self.analyzer.analyze_message(text)

            if result:
                return {
                    "success": True,
                    "result": result,
                    "variant_name": variant.name,
                    "processing_time": 0,  # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
                }
            else:
                return {"success": False, "error": "Analysis failed"}

        except Exception as e:
            return {"success": False, "error": str(e)}

    def _evaluate_analysis_quality(
        self, analysis: Dict[str, Any], original_text: str
    ) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º."""
        scores = {
            "completeness": 0.0,  # –ü–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            "relevance": 0.0,  # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            "specificity": 0.0,  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å
            "length_appropriateness": 0.0,  # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω—ã
            "overall": 0.0,
        }

        if not analysis.get("success") or not analysis.get("result"):
            return scores

        result = analysis["result"]

        # –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã (–µ—Å—Ç—å –ª–∏ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è)
        required_fields = ["summary", "sentiment", "topics", "keywords"]
        present_fields = sum(1 for field in required_fields if result.get(field))
        scores["completeness"] = present_fields / len(required_fields)

        # –û—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã —Ä–µ–∑—é–º–µ
        if result.get("summary"):
            summary_len = len(result["summary"].split())
            if 10 <= summary_len <= 50:  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ–∑—é–º–µ
                scores["length_appropriateness"] = 1.0
            elif 5 <= summary_len <= 80:
                scores["length_appropriateness"] = 0.7
            else:
                scores["length_appropriateness"] = 0.3

        # –û—Ü–µ–Ω–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç–∏ (–∏–∑–±–µ–≥–∞–Ω–∏–µ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑)
        if result.get("summary"):
            generic_phrases = [
                "–≤–∞–∂–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å",
                "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
                "–∞–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞",
            ]
            summary_lower = result["summary"].lower()
            generic_count = sum(
                1 for phrase in generic_phrases if phrase in summary_lower
            )
            scores["specificity"] = max(0, 1.0 - (generic_count * 0.3))

        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–º
        if result.get("topics") and isinstance(result["topics"], list):
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —Ç–µ–º—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–º–∏
            generic_topics = ["–Ω–æ–≤–æ—Å—Ç–∏", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "—Å–æ–±—ã—Ç–∏—è", "–∞–∫—Ç—É–∞–ª—å–Ω–æ–µ"]
            specific_topics = [
                t for t in result["topics"] if t.lower() not in generic_topics
            ]
            if result["topics"]:
                scores["relevance"] = len(specific_topics) / len(result["topics"])

        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        scores["overall"] = np.mean(
            [
                scores["completeness"],
                scores["relevance"],
                scores["specificity"],
                scores["length_appropriateness"],
            ]
        )

        return scores

    async def run_ab_test(self, sample_size: int = 30) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤."""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤")
        print(f"üìä –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {sample_size} —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –≤–∞—Ä–∏–∞–Ω—Ç")
        print(f"üî¨ –í–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(self.prompt_variants)}")
        print("=" * 60)

        if not self.analyzer:
            print("‚ùå LLM –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return self.results

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
        test_texts = self._get_test_texts(sample_size * len(self.prompt_variants))
        if not test_texts:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã")
            return self.results

        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        random.shuffle(test_texts)

        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –ø–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º
        texts_per_variant = len(test_texts) // len(self.prompt_variants)

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        for i, variant in enumerate(self.prompt_variants):
            print(
                f"\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ '{variant.name}' ({variant.description})"
            )

            # –í—ã–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
            start_idx = i * texts_per_variant
            end_idx = start_idx + texts_per_variant
            variant_texts = test_texts[start_idx:end_idx]

            variant_results = []
            successful_analyses = 0

            for j, text_data in enumerate(variant_texts):
                if j % 10 == 0:
                    print(f"  üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {j}/{len(variant_texts)} —Ç–µ–∫—Å—Ç–æ–≤...")

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                analysis = await self._analyze_with_variant(text_data["text"], variant)

                if analysis.get("success"):
                    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                    quality_scores = self._evaluate_analysis_quality(
                        analysis, text_data["text"]
                    )

                    variant_results.append(
                        {
                            "message_id": text_data["message_id"],
                            "analysis": analysis["result"],
                            "quality_scores": quality_scores,
                        }
                    )
                    successful_analyses += 1

            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞
            if variant_results:
                avg_scores = {}
                for metric in [
                    "completeness",
                    "relevance",
                    "specificity",
                    "length_appropriateness",
                    "overall",
                ]:
                    scores = [r["quality_scores"][metric] for r in variant_results]
                    avg_scores[metric] = {
                        "mean": np.mean(scores),
                        "std": np.std(scores),
                        "min": np.min(scores),
                        "max": np.max(scores),
                    }

                self.results["test_variants"][variant.name] = {
                    "variant_info": {
                        "name": variant.name,
                        "description": variant.description,
                        "temperature": variant.temperature,
                        "max_tokens": variant.max_tokens,
                    },
                    "sample_size": len(variant_results),
                    "success_rate": successful_analyses / len(variant_texts),
                    "quality_metrics": avg_scores,
                    "sample_results": variant_results[:5],  # –ü–µ—Ä–≤—ã–µ 5 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                }

                print(
                    f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {successful_analyses}/{len(variant_texts)}"
                )
                print(
                    f"  üìä –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {avg_scores['overall']['mean']:.3f}"
                )
            else:
                print(
                    f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ {variant.name}"
                )

        # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        self._compare_variants()

        return self.results

    def _compare_variants(self):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤."""
        print(f"\nüìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")

        if len(self.results["test_variants"]) < 2:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            return

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º
        comparison_metrics = [
            "completeness",
            "relevance",
            "specificity",
            "length_appropriateness",
            "overall",
        ]

        comparisons = {}

        for metric in comparison_metrics:
            metric_results = {}

            for variant_name, variant_data in self.results["test_variants"].items():
                if (
                    "quality_metrics" in variant_data
                    and metric in variant_data["quality_metrics"]
                ):
                    metric_results[variant_name] = variant_data["quality_metrics"][
                        metric
                    ]["mean"]

            if metric_results:
                # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –∏ —Ö—É–¥—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç—ã
                best_variant = max(metric_results.items(), key=lambda x: x[1])
                worst_variant = min(metric_results.items(), key=lambda x: x[1])

                comparisons[metric] = {
                    "best": {"variant": best_variant[0], "score": best_variant[1]},
                    "worst": {"variant": worst_variant[0], "score": worst_variant[1]},
                    "all_scores": metric_results,
                }

                print(f"  üìà {metric.upper()}:")
                print(f"    ü•á –õ—É—á—à–∏–π: {best_variant[0]} ({best_variant[1]:.3f})")
                print(f"    üìâ –•—É–¥—à–∏–π: {worst_variant[0]} ({worst_variant[1]:.3f})")

        self.results["comparisons"] = comparisons

        # –û–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        overall_scores = {}
        for variant_name, variant_data in self.results["test_variants"].items():
            if (
                "quality_metrics" in variant_data
                and "overall" in variant_data["quality_metrics"]
            ):
                overall_scores[variant_name] = variant_data["quality_metrics"][
                    "overall"
                ]["mean"]

        if overall_scores:
            ranked_variants = sorted(
                overall_scores.items(), key=lambda x: x[1], reverse=True
            )

            print(f"\nüèÜ –û–ë–©–ò–ô –†–ï–ô–¢–ò–ù–ì –í–ê–†–ò–ê–ù–¢–û–í:")
            for i, (variant, score) in enumerate(ranked_variants, 1):
                print(f"  {i}. {variant}: {score:.3f}")

            self.results["summary"] = {
                "best_overall_variant": ranked_variants[0][0],
                "best_overall_score": ranked_variants[0][1],
                "ranking": ranked_variants,
            }

    def save_results(self, output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"
    )

    parser.add_argument(
        "--sample-size",
        type=int,
        default=20,
        help="–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 20)",
    )

    parser.add_argument(
        "--db", type=Path, default=Path("data/storage.db"), help="–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
    )

    parser.add_argument(
        "--output",
        type=Path,
        default=Path("evaluation/ab_test_results.json"),
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã
    if not SYSTEM_AVAILABLE:
        print("‚ùå –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    tester = ABPromptTester(args.db)
    results = asyncio.run(tester.run_ab_test(args.sample_size))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    tester.save_results(args.output)

    print(f"\nüéâ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    main()
