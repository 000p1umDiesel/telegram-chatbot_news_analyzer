#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫: BERTScore –∏ semantic similarity.
"""

from typing import List, Dict, Any
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from .base_evaluator import BaseEvaluator

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ bert_score
try:
    import importlib.util

    bert_score_module = importlib.util.find_spec("bert_score")
    if bert_score_module is not None:
        from bert_score import score as bert_score

        BERT_SCORE_AVAILABLE = True
    else:
        bert_score = None
        BERT_SCORE_AVAILABLE = False
except ImportError:
    bert_score = None
    BERT_SCORE_AVAILABLE = False


class SemanticTest(BaseEvaluator):
    """–¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫."""

    def __init__(self, db_config: dict = None):
        super().__init__(db_config)
        self._load_models()

    def _load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."""
        try:
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            try:
                self.sentence_model = SentenceTransformer(
                    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
                )
            except Exception as e:
                print(
                    f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å paraphrase-multilingual-MiniLM-L12-v2: {e}"
                )
                print("üîÑ –ü—Ä–æ–±—É—é fallback: all-MiniLM-L6-v2...")
                self.sentence_model = SentenceTransformer(
                    "sentence-transformers/all-MiniLM-L6-v2"
                )
            print("‚úÖ –ú–æ–¥–µ–ª—å semantic similarity –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ semantic similarity –º–æ–¥–µ–ª–∏: {e}")
            self.sentence_model = None

    def run_test(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤."""
        print("üîç –ó–∞–ø—É—Å–∫ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫...")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ —Å–∞–º–º–∞—Ä–∏
        texts = [item["text"] for item in data]
        summaries = [item["summary"] for item in data]

        metrics = {}

        # Semantic similarity
        if self.sentence_model is not None:
            semantic_results = self._compute_semantic_similarity(texts, summaries)
            metrics.update(semantic_results)

        # BERTScore
        if BERT_SCORE_AVAILABLE:
            bert_results = self._compute_bert_scores(texts, summaries)
            metrics.update(bert_results)
        else:
            print("‚ö†Ô∏è BERTScore –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        self.results["metrics"] = metrics
        self.results["details"] = {
            "samples_processed": len(data),
            "bert_score_available": BERT_SCORE_AVAILABLE,
            "semantic_model_available": self.sentence_model is not None,
        }

        return self.results

    def _compute_semantic_similarity(
        self, texts: List[str], summaries: List[str]
    ) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞."""
        print("üîÑ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ semantic similarity...")

        similarities = []

        if self.sentence_model is not None:
            for text, summary in zip(texts, summaries):
                if text and summary:
                    text_snippet = text[:500]
                    embeddings = self.sentence_model.encode([text_snippet, summary])
                    similarity = float(
                        np.dot(embeddings[0], embeddings[1])
                        / (
                            np.linalg.norm(embeddings[0])
                            * np.linalg.norm(embeddings[1])
                        )
                    )
                    similarities.append(similarity)

        return {
            "semantic_similarity_mean": (
                float(np.mean(similarities)) if similarities else 0.0
            ),
            "semantic_similarity_std": (
                float(np.std(similarities)) if similarities else 0.0
            ),
            "semantic_similarity_min": (
                float(np.min(similarities)) if similarities else 0.0
            ),
            "semantic_similarity_max": (
                float(np.max(similarities)) if similarities else 0.0
            ),
        }

    def _compute_bert_scores(
        self, texts: List[str], summaries: List[str]
    ) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ BERTScore –º–µ—Ç—Ä–∏–∫."""
        print("üîÑ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ BERTScore...")
        if not BERT_SCORE_AVAILABLE or bert_score is None:
            print("‚ö†Ô∏è BERTScore –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
            return {
                "bert_score_precision_mean": 0.0,
                "bert_score_recall_mean": 0.0,
                "bert_score_f1_mean": 0.0,
                "bert_score_precision_std": 0.0,
                "bert_score_recall_std": 0.0,
                "bert_score_f1_std": 0.0,
            }
        references = []
        for text in texts:
            sentences = text.split(".")[:3]
            reference = ". ".join(sentences).strip()
            references.append(reference if reference else text[:200])
        P, R, F1 = bert_score(summaries, references, lang="ru", verbose=False)
        return {
            "bert_score_precision_mean": float(P.mean()),
            "bert_score_recall_mean": float(R.mean()),
            "bert_score_f1_mean": float(F1.mean()),
            "bert_score_precision_std": float(P.std()),
            "bert_score_recall_std": float(R.std()),
            "bert_score_f1_std": float(F1.std()),
        }

    def _generate_summary(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∞."""
        metrics = self.results["metrics"]

        semantic_sim = metrics.get("semantic_similarity_mean", 0)
        bert_f1 = metrics.get("bert_score_f1_mean", 0)

        return f"Semantic Similarity: {semantic_sim:.3f}, BERTScore F1: {bert_f1:.3f}"

    def _generate_recommendations(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫."""
        metrics = self.results["metrics"]
        recommendations = []

        semantic_sim = metrics.get("semantic_similarity_mean", 0)
        bert_f1 = metrics.get("bert_score_f1_mean", 0)

        if semantic_sim < 0.6:
            recommendations.append(
                "–ù–∏–∑–∫–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ - —É–ª—É—á—à–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–º—ã—Å–ª–∞ —Å—É–º–º–∞—Ä–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É"
            )

        if bert_f1 < 0.7:
            recommendations.append(
                "–ù–∏–∑–∫–∏–π BERTScore F1 - —Ä–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ –∫–∞—á–µ—Å—Ç–≤–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è"
            )

        if semantic_sim > 0.8:
            recommendations.append("–û—Ç–ª–∏—á–Ω–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ!")

        if bert_f1 > 0.85:
            recommendations.append(
                "–ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π BERTScore - –º–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç"
            )

        return recommendations
