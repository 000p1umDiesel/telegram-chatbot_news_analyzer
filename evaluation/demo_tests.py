#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∫–∞–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Å–∏—Å—Ç–µ–º—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
–ó–∞–ø—É—Å–∫–∞–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ —Ç–µ—Å—Ç–æ–≤ —Å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
"""

import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
import random


class DemoTester:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""

    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "demo_mode": True,
            "tests": {},
        }

    def generate_synthetic_news(self, count: int = 10) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
        templates = [
            "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –†–æ—Å—Å–∏–∏ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–æ {rate}% –¥–ª—è –±–æ—Ä—å–±—ã —Å –∏–Ω—Ñ–ª—è—Ü–∏–µ–π. –†–µ—à–µ–Ω–∏–µ –≤—ã–∑–≤–∞–ª–æ {reaction} —Ä–µ–∞–∫—Ü–∏—é —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Ä—ã–Ω–∫–∞.",
            "–í {city} –æ—Ç–∫—Ä—ã–ª—Å—è –Ω–æ–≤—ã–π {facility}, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–∞–Ω–µ—Ç –∫—Ä—É–ø–Ω–µ–π—à–∏–º –≤ —Ä–µ–≥–∏–æ–Ω–µ. –ü—Ä–æ–µ–∫—Ç –æ–±–æ—à–µ–ª—Å—è –≤ {cost} –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ —Ä—É–±–ª–µ–π.",
            "–†–æ—Å—Å–∏–π—Å–∫–∏–µ —É—á–µ–Ω—ã–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –Ω–æ–≤—É—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é {tech}, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç {benefit}. –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–Ω—è–ª–∞ {years} –ª–µ—Ç.",
            "–ü–æ–≥–æ–¥–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –≤ {region} —É—Ö—É–¥—à–∏–ª–∏—Å—å –∏–∑-–∑–∞ {weather}. –ú–µ—Ç–µ–æ—Ä–æ–ª–æ–≥–∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—Ç –æ {warning}.",
            "–ö—Ä—É–ø–Ω–∞—è IT-–∫–æ–º–ø–∞–Ω–∏—è {company} –æ–±—ä—è–≤–∏–ª–∞ –æ –∑–∞–ø—É—Å–∫–µ –Ω–æ–≤–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞ {service}. –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω –ø—Ä–∏–≤–ª–µ—á–µ—Ç {users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.",
        ]

        variables = {
            "rate": ["15", "16", "17", "18"],
            "reaction": ["—Å–º–µ—à–∞–Ω–Ω—É—é", "–ø–æ–∑–∏—Ç–∏–≤–Ω—É—é", "–Ω–µ–≥–∞—Ç–∏–≤–Ω—É—é", "–æ—Å—Ç–æ—Ä–æ–∂–Ω—É—é"],
            "city": ["–ú–æ—Å–∫–≤–µ", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥–µ", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–µ"],
            "facility": [
                "—Ç–æ—Ä–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä",
                "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –∫–æ–º–ø–ª–µ–∫—Å",
                "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä",
                "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–∞–º–ø—É—Å",
            ],
            "cost": ["5", "10", "15", "20"],
            "tech": [
                "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
                "–∫–≤–∞–Ω—Ç–æ–≤—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π",
                "–±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
                "–Ω–∞–Ω–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
            ],
            "benefit": [
                "—Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—É",
                "—É–ª—É—á—à–∏—Ç—å —ç–∫–æ–ª–æ–≥–∏—é",
                "–ø–æ–≤—ã—Å–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞",
            ],
            "years": ["3", "5", "7", "10"],
            "region": ["–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –†–æ—Å—Å–∏–∏", "–°–∏–±–∏—Ä–∏", "–î–∞–ª—å–Ω–µ–≥–æ –í–æ—Å—Ç–æ–∫–∞", "–£—Ä–∞–ª–∞"],
            "weather": ["—Ü–∏–∫–ª–æ–Ω–∞", "–∞–Ω—Ç–∏—Ü–∏–∫–ª–æ–Ω–∞", "–∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω–æ–≥–æ —Ñ—Ä–æ–Ω—Ç–∞"],
            "warning": [
                "—Å–∏–ª—å–Ω–æ–º –≤–µ—Ç—Ä–µ",
                "–≥–æ–ª–æ–ª–µ–¥–µ",
                "—Å–Ω–µ–≥–æ–ø–∞–¥–∞—Ö",
                "—Ä–µ–∑–∫–æ–º –ø–æ—Ö–æ–ª–æ–¥–∞–Ω–∏–∏",
            ],
            "company": ["–Ø–Ω–¥–µ–∫—Å", "–°–±–µ—Ä", "–ú–¢–°", "–†–æ—Å—Ç–µ–ª–µ–∫–æ–º"],
            "service": [
                "–¥–ª—è –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞",
                "–≤ —Å—Ñ–µ—Ä–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è",
                "–¥–ª—è –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —É—Å–ª—É–≥",
            ],
            "users": ["–º–∏–ª–ª–∏–æ–Ω", "–¥–≤–∞ –º–∏–ª–ª–∏–æ–Ω–∞", "–ø—è—Ç—å –º–∏–ª–ª–∏–æ–Ω–æ–≤"],
        }

        news = []
        for i in range(count):
            template = random.choice(templates)

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            text = template
            for var, options in variables.items():
                if f"{{{var}}}" in text:
                    text = text.replace(f"{{{var}}}", random.choice(options))

            news.append({"id": f"demo_{i}", "text": text, "channel": "demo_channel"})

        return news

    def simulate_llm_analysis(self, text: str) -> Dict[str, Any]:
        """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ LLM –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        positive_words = ["–Ω–æ–≤—ã–π", "—É–ª—É—á—à–∏—Ç—å", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "—É—Å–ø–µ—Ö", "—Ä–æ—Å—Ç"]
        negative_words = ["—É—Ö—É–¥—à–∏–ª–∏—Å—å", "–ø—Ä–æ–±–ª–µ–º–∞", "–∫—Ä–∏–∑–∏—Å", "–ø–∞–¥–µ–Ω–∏–µ", "—Ä–∏—Å–∫"]

        pos_count = sum(1 for word in positive_words if word in text.lower())
        neg_count = sum(1 for word in negative_words if word in text.lower())

        if pos_count > neg_count:
            sentiment = "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è"
        elif neg_count > pos_count:
            sentiment = "–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è"
        else:
            sentiment = "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–ø–µ—Ä–≤—ã–µ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        sentences = text.split(".")
        summary = ". ".join(sentences[:2]).strip() + "."

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        words = text.lower().split()
        important_words = [w for w in words if len(w) > 4 and w.isalpha()]
        keywords = random.sample(important_words, min(5, len(important_words)))

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–º—ã
        topic_mapping = {
            "–±–∞–Ω–∫": "—ç–∫–æ–Ω–æ–º–∏–∫–∞",
            "—Å—Ç–∞–≤–∫–∞": "—Ñ–∏–Ω–∞–Ω—Å—ã",
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è": "–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏",
            "—É—á–µ–Ω—ã–µ": "–Ω–∞—É–∫–∞",
            "–ø–æ–≥–æ–¥–∞": "–∫–ª–∏–º–∞—Ç",
            "–∫–æ–º–ø–∞–Ω–∏—è": "–±–∏–∑–Ω–µ—Å",
        }

        topics = []
        for word, topic in topic_mapping.items():
            if word in text.lower():
                topics.append(topic)

        if not topics:
            topics = ["–æ–±—â–µ—Å—Ç–≤–æ"]

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö–µ—à—Ç–µ–≥–∏
        hashtags = [f"#{topic}" for topic in topics[:3]]

        return {
            "summary": summary,
            "sentiment": sentiment,
            "topics": topics,
            "keywords": keywords,
            "hashtags": hashtags,
        }

    def demo_comprehensive_test(self) -> Dict[str, Any]:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ."""
        print("\nüîç –î–µ–º–æ: –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        news_items = self.generate_synthetic_news(20)

        # –°–∏–º—É–ª–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑
        analyses = []
        for item in news_items:
            analysis = self.simulate_llm_analysis(item["text"])
            analyses.append({"original": item, "analysis": analysis})

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_scores = []
        hallucination_count = 0
        sentiment_consistency = 0

        for analysis in analyses:
            # –°–∏–º—É–ª–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏
            completeness = random.uniform(0.7, 1.0)
            relevance = random.uniform(0.6, 0.95)

            # –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π (10% —Å–ª—É—á–∞–µ–≤)
            has_hallucination = random.random() < 0.1
            if has_hallucination:
                hallucination_count += 1

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å sentiment
            if analysis["analysis"]["sentiment"] in [
                "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è",
                "–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è",
                "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è",
            ]:
                sentiment_consistency += 1

            quality_scores.append(
                {
                    "completeness": completeness,
                    "relevance": relevance,
                    "has_hallucination": has_hallucination,
                }
            )

        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        avg_completeness = sum(s["completeness"] for s in quality_scores) / len(
            quality_scores
        )
        avg_relevance = sum(s["relevance"] for s in quality_scores) / len(
            quality_scores
        )
        hallucination_rate = hallucination_count / len(analyses)
        sentiment_consistency_rate = sentiment_consistency / len(analyses)

        overall_score = (
            avg_completeness
            + avg_relevance
            + (1 - hallucination_rate)
            + sentiment_consistency_rate
        ) / 4

        results = {
            "status": "passed",
            "samples_tested": len(analyses),
            "metrics": {
                "avg_completeness": avg_completeness,
                "avg_relevance": avg_relevance,
                "hallucination_rate": hallucination_rate,
                "sentiment_consistency": sentiment_consistency_rate,
                "overall_score": overall_score,
            },
            "sample_analyses": analyses[:3],  # –ü–µ—Ä–≤—ã–µ 3 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        }

        print(f"  üìä –û–±—Ä–∞–∑—Ü–æ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {len(analyses)}")
        print(f"  ‚úÖ –ü–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {avg_completeness:.3f}")
        print(f"  üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_relevance:.3f}")
        print(f"  üß† –£—Ä–æ–≤–µ–Ω—å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {hallucination_rate:.1%}")
        print(f"  üòä –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å sentiment: {sentiment_consistency_rate:.1%}")
        print(f"  üèÜ –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {overall_score:.3f}")

        return results

    def demo_performance_test(self) -> Dict[str, Any]:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        print("\n‚ö° –î–µ–º–æ: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
        operations = [
            ("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", 0.1, 0.3),
            ("LLM –∞–Ω–∞–ª–∏–∑", 2.0, 5.0),
            ("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", 0.05, 0.15),
            ("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è", 0.2, 0.8),
        ]

        performance_results = {}
        total_time = 0

        for op_name, min_time, max_time in operations:
            # –°–∏–º—É–ª–∏—Ä—É–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            op_time = random.uniform(min_time, max_time)
            time.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Ä–µ–∞–ª–∏–∑–º–∞

            performance_results[op_name] = {
                "avg_time": op_time,
                "operations_per_minute": 60 / op_time if op_time > 0 else 0,
            }
            total_time += op_time

            print(f"  üîÑ {op_name}: {op_time:.2f}—Å ({60/op_time:.1f} –æ–ø/–º–∏–Ω)")

        # –û–±—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        throughput = 60 / total_time if total_time > 0 else 0

        results = {
            "status": "passed",
            "total_time": total_time,
            "throughput_per_minute": throughput,
            "operations": performance_results,
        }

        print(f"  üèÅ –û–±—â–µ–µ –≤—Ä–µ–º—è —Ü–∏–∫–ª–∞: {total_time:.2f}—Å")
        print(f"  üöÄ –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {throughput:.1f} —Ü–∏–∫–ª–æ–≤/–º–∏–Ω")

        return results

    def demo_rouge_metrics(self) -> Dict[str, Any]:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç ROUGE –º–µ—Ç—Ä–∏–∫–∏."""
        print("\nüìä –î–µ–º–æ: ROUGE –º–µ—Ç—Ä–∏–∫–∏")

        # –°–∏–º—É–ª–∏—Ä—É–µ–º ROUGE scores –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        rouge_scores = []

        for i in range(10):
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ, –Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ ROUGE scores
            rouge1_f1 = random.uniform(0.2, 0.6)
            rouge2_f1 = random.uniform(
                0.1, rouge1_f1 * 0.8
            )  # ROUGE-2 –æ–±—ã—á–Ω–æ –Ω–∏–∂–µ ROUGE-1
            rougeL_f1 = random.uniform(rouge2_f1, rouge1_f1)  # ROUGE-L –º–µ–∂–¥—É –Ω–∏–º–∏

            rouge_scores.append(
                {"rouge1_f1": rouge1_f1, "rouge2_f1": rouge2_f1, "rougeL_f1": rougeL_f1}
            )

        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        avg_rouge1 = sum(s["rouge1_f1"] for s in rouge_scores) / len(rouge_scores)
        avg_rouge2 = sum(s["rouge2_f1"] for s in rouge_scores) / len(rouge_scores)
        avg_rougeL = sum(s["rougeL_f1"] for s in rouge_scores) / len(rouge_scores)

        results = {
            "status": "passed",
            "samples_evaluated": len(rouge_scores),
            "metrics": {
                "rouge1_f1": avg_rouge1,
                "rouge2_f1": avg_rouge2,
                "rougeL_f1": avg_rougeL,
            },
        }

        print(f"  üìù –û–±—Ä–∞–∑—Ü–æ–≤ –æ—Ü–µ–Ω–µ–Ω–æ: {len(rouge_scores)}")
        print(f"  üìä ROUGE-1 F1: {avg_rouge1:.3f}")
        print(f"  üìä ROUGE-2 F1: {avg_rouge2:.3f}")
        print(f"  üìä ROUGE-L F1: {avg_rougeL:.3f}")

        return results

    def demo_ab_testing(self) -> Dict[str, Any]:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤."""
        print("\nüß™ –î–µ–º–æ: A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤")

        variants = [
            {"name": "original", "description": "–ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç"},
            {"name": "structured", "description": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç"},
            {"name": "quality_focused", "description": "–ü—Ä–æ–º–ø—Ç —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ"},
        ]

        variant_results = {}

        for variant in variants:
            # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
            # Structured –∏ quality_focused –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            base_score = 0.7
            if variant["name"] == "structured":
                base_score = 0.75
            elif variant["name"] == "quality_focused":
                base_score = 0.8

            scores = {
                "completeness": random.uniform(base_score - 0.1, base_score + 0.1),
                "relevance": random.uniform(base_score - 0.05, base_score + 0.15),
                "specificity": random.uniform(base_score - 0.15, base_score + 0.05),
                "overall": 0,
            }
            scores["overall"] = (
                scores["completeness"] + scores["relevance"] + scores["specificity"]
            ) / 3

            variant_results[variant["name"]] = {
                "description": variant["description"],
                "scores": scores,
                "sample_size": 15,
            }

            print(
                f"  üî¨ {variant['name']}: {scores['overall']:.3f} ({variant['description']})"
            )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
        best_variant = max(
            variant_results.items(), key=lambda x: x[1]["scores"]["overall"]
        )

        results = {
            "status": "passed",
            "variants_tested": len(variants),
            "best_variant": best_variant[0],
            "best_score": best_variant[1]["scores"]["overall"],
            "variant_results": variant_results,
        }

        print(
            f"  üèÜ –õ—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç: {best_variant[0]} ({best_variant[1]['scores']['overall']:.3f})"
        )

        return results

    def run_demo_suite(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
        print("üé≠ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        print("=" * 50)
        print("üìù –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
        print("üîß –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ —Ç–µ—Å—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Å –≤–∞—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        print("=" * 50)

        start_time = time.time()

        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –¥–µ–º–æ-—Ç–µ—Å—Ç—ã
        self.results["tests"]["comprehensive"] = self.demo_comprehensive_test()
        self.results["tests"]["performance"] = self.demo_performance_test()
        self.results["tests"]["rouge_metrics"] = self.demo_rouge_metrics()
        self.results["tests"]["ab_testing"] = self.demo_ab_testing()

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = time.time() - start_time
        passed_tests = sum(
            1
            for test in self.results["tests"].values()
            if test.get("status") == "passed"
        )

        self.results["summary"] = {
            "total_tests": len(self.results["tests"]),
            "passed_tests": passed_tests,
            "execution_time": total_time,
            "success_rate": passed_tests / len(self.results["tests"]),
        }

        print("\n" + "=" * 50)
        print("üìã –ò–¢–û–ì–ò –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò:")
        print(f"‚úÖ –¢–µ—Å—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {passed_tests}/{len(self.results['tests'])}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.1f}—Å")
        print(f"üìä –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {self.results['summary']['success_rate']:.1%}")

        print(f"\nüéØ –ö–õ–Æ–ß–ï–í–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:")
        print(f"‚Ä¢ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞")
        print(f"‚Ä¢ –î–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ LLM")
        print(f"‚Ä¢ ROUGE –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
        print(f"‚Ä¢ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        print(f"‚Ä¢ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤")
        print(f"‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤")

        return self.results

    def save_demo_results(self, output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")


def main():
    print("üé≠ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")

    # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-—Ç–µ—Å—Ç–µ—Ä
    demo = DemoTester()

    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é
    results = demo.run_demo_suite()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_path = Path("evaluation/demo_results.json")
    demo.save_demo_results(output_path)

    print(f"\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"\nüìñ –î–ª—è –∏–∑—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤:")
    print(f"‚Ä¢ –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ evaluation/README.md")
    print(f"‚Ä¢ –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python evaluation/run_all_tests.py --quick")
    print(f"‚Ä¢ –ò–∑—É—á–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –≤ –ø–∞–ø–∫–µ evaluation/")


if __name__ == "__main__":
    main()
