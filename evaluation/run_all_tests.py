#!/usr/bin/env python3
"""
Unified Test Runner for News Analysis Evaluation System

–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤:
    python evaluation/run_all_tests.py --all --samples 100

–ó–∞–ø—É—Å–∫ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤:
    python evaluation/run_all_tests.py --tests rouge semantic hashtag --samples 50

–ó–∞–ø—É—Å–∫ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ë–î:
    python evaluation/run_all_tests.py --tests performance --db-config custom_db.json
"""

import asyncio
import argparse
import json
import sys
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent))

# –ò–º–ø–æ—Ä—Ç—ã —Ç–µ—Å—Ç–æ–≤
from evaluation.tests.rouge_test import ROUGETest
from evaluation.tests.semantic_test import SemanticTest
from evaluation.tests.hallucination_test import HallucinationTest
from evaluation.tests.hashtag_test import HashtagTest
from evaluation.tests.sentiment_test import SentimentTest
from evaluation.tests.ab_prompt_test import ABPromptTest
from evaluation.tests.performance_test import PerformanceTest

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class UnifiedTestRunner:
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏"""

    def __init__(self, db_config_path: str = "db_config.json"):
        self.db_config_path = db_config_path
        self.test_registry = {
            "rouge": ROUGETest,
            "semantic": SemanticTest,
            "hallucination": HallucinationTest,
            "hashtag": HashtagTest,
            "sentiment": SentimentTest,
            "ab_prompt": ABPromptTest,
            "performance": PerformanceTest,
        }

    def load_db_config(self) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if Path(self.db_config_path).exists():
                with open(self.db_config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ë–î –∏–∑ {self.db_config_path}")
                return config
            else:
                logger.warning(
                    f"–§–∞–π–ª {self.db_config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
                )
                return {
                    "host": "localhost",
                    "port": 5432,
                    "database": "news_analyzer",
                    "user": "postgres",
                    "password": "postgres",
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ë–î: {e}")
            return None

    async def run_test(
        self, test_name: str, samples: int = 100
    ) -> Optional[Dict[str, Any]]:
        """–ó–∞–ø—É—Å–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞"""
        if test_name not in self.test_registry:
            logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–µ—Å—Ç: {test_name}")
            return None

        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞: {test_name} ({samples} samples)")

        try:
            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Ç–µ—Å—Ç–µ—Ä–∞
            test_class = self.test_registry[test_name]

            # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º db_config
            db_config = self.load_db_config()
            if db_config is None:
                logger.error(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ë–î –¥–ª—è —Ç–µ—Å—Ç–∞ {test_name}"
                )
                return None
            evaluator = test_class(db_config)

            # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
            start_time = time.time()

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞
            test_data = await evaluator.fetch_test_data(samples)

            # –í—Å–µ —Ç–µ—Å—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –º–µ—Ç–æ–¥ run_test
            results = evaluator.run_test(test_data)

            execution_time = time.time() - start_time

            logger.info(f"‚úÖ –¢–µ—Å—Ç {test_name} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {execution_time:.2f}s")

            return {
                "test_name": test_name,
                "execution_time": execution_time,
                "samples": samples,
                "results": results,
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ {test_name}: {e}")
            return None

    async def run_multiple_tests(
        self, test_names: List[str], samples: int = 100
    ) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤"""
        logger.info(f"üìä –ó–∞–ø—É—Å–∫ {len(test_names)} —Ç–µ—Å—Ç–æ–≤: {', '.join(test_names)}")

        all_results = {}
        total_start_time = time.time()

        for test_name in test_names:
            result = await self.run_test(test_name, samples)
            if result:
                all_results[test_name] = result
            else:
                logger.warning(f"‚ö†Ô∏è –¢–µ—Å—Ç {test_name} –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")

        total_execution_time = time.time() - total_start_time

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        summary = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_tests": len(test_names),
            "successful_tests": len(all_results),
            "failed_tests": len(test_names) - len(all_results),
            "total_execution_time": total_execution_time,
            "samples_per_test": samples,
            "results": all_results,
        }

        return summary

    def save_results(self, results: Dict[str, Any], output_file: Optional[str] = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª"""
        if output_file is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"evaluation/test_results_{timestamp}.json"

        try:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

    def print_summary(self, results: Dict[str, Any]):
        """–í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        print("\n" + "=" * 80)
        print("üéØ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ")
        print("=" * 80)

        print(f"‚è∞ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {results['timestamp']}")
        print(f"üìä –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {results['total_tests']}")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö: {results['successful_tests']}")
        print(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö: {results['failed_tests']}")
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {results['total_execution_time']:.2f}s")
        print(f"üî¢ –û–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ —Ç–µ—Å—Ç: {results['samples_per_test']}")

        print("\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –¢–ï–°–¢–ê–ú:")
        print("-" * 50)

        for test_name, test_data in results["results"].items():
            print(f"\nüß™ {test_name.upper()}:")
            print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {test_data['execution_time']:.2f}s")

            if "results" in test_data and test_data["results"]:
                test_results = test_data["results"]

                # –†–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
                if test_name == "rouge":
                    avg_rouge = test_results.get("average_rouge_scores", {})
                    print(f"   üìä ROUGE-1: {avg_rouge.get('rouge1_f', 0):.3f}")
                    print(f"   üìä ROUGE-2: {avg_rouge.get('rouge2_f', 0):.3f}")
                    print(f"   üìä ROUGE-L: {avg_rouge.get('rougeL_f', 0):.3f}")

                elif test_name == "semantic":
                    print(
                        f"   üìä BERTScore F1: {test_results.get('average_bertscore_f1', 0):.3f}"
                    )
                    print(
                        f"   üìä Semantic Similarity: {test_results.get('average_semantic_similarity', 0):.3f}"
                    )

                elif test_name == "hallucination":
                    print(
                        f"   üìä Hallucination Rate: {test_results.get('hallucination_rate', 0):.3f}"
                    )
                    print(
                        f"   üìä Confidence: {test_results.get('average_confidence', 0):.3f}"
                    )

                elif test_name == "hashtag":
                    print(f"   üìä Accuracy: {test_results.get('accuracy', 0):.3f}")
                    print(f"   üìä Precision: {test_results.get('precision', 0):.3f}")
                    print(f"   üìä Recall: {test_results.get('recall', 0):.3f}")

                elif test_name == "sentiment":
                    print(f"   üìä Accuracy: {test_results.get('accuracy', 0):.3f}")
                    print(f"   üìä F1-Score: {test_results.get('f1_score', 0):.3f}")

                elif test_name == "ab_prompt":
                    for strategy, metrics in test_results.items():
                        if isinstance(metrics, dict):
                            print(
                                f"   üìä {strategy}: Quality={metrics.get('quality', 0):.3f}"
                            )

                elif test_name == "performance":
                    print(
                        f"   üìä Avg Response Time: {test_results.get('average_response_time', 0):.3f}s"
                    )
                    print(
                        f"   üìä Memory Usage: {test_results.get('peak_memory_mb', 0):.1f}MB"
                    )

        print("\n" + "=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description="Unified Test Runner for News Analysis"
    )

    parser.add_argument(
        "--tests",
        nargs="+",
        choices=[
            "rouge",
            "semantic",
            "hallucination",
            "hashtag",
            "sentiment",
            "ab_prompt",
            "performance",
        ],
        help="Specific tests to run",
    )

    parser.add_argument("--all", action="store_true", help="Run all available tests")

    parser.add_argument(
        "--samples",
        type=int,
        default=100,
        help="Number of samples per test (default: 100)",
    )

    parser.add_argument(
        "--db-config",
        type=str,
        default="db_config.json",
        help="Database configuration file (default: db_config.json)",
    )

    parser.add_argument(
        "--output", type=str, help="Output file for results (default: auto-generated)"
    )

    parser.add_argument(
        "--no-save", action="store_true", help="Do not save results to file"
    )

    args = parser.parse_args()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ç–µ—Å—Ç—ã –∑–∞–ø—É—Å–∫–∞—Ç—å
    if args.all:
        test_names = list(
            [
                "rouge",
                "semantic",
                "hallucination",
                "hashtag",
                "sentiment",
                "ab_prompt",
                "performance",
            ]
        )
    elif args.tests:
        test_names = args.tests
    else:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ --all –∏–ª–∏ --tests —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ç–µ—Å—Ç–∞–º–∏")
        parser.print_help()
        return

    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–µ—Ä
    runner = UnifiedTestRunner(args.db_config)

    async def run_tests():
        results = await runner.run_multiple_tests(test_names, args.samples)

        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
        runner.print_summary(results)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not args.no_save:
            runner.save_results(results, args.output)

        return results

    # –ó–∞–ø—É—Å–∫
    try:
        asyncio.run(run_tests())
    except KeyboardInterrupt:
        logger.info("üõë –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
