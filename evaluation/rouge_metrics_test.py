#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ROUGE –º–µ—Ç—Ä–∏–∫.
–¢—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏: pip install rouge-score
"""

import argparse
import sqlite3
import json
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime
import numpy as np

try:
    from rouge_score import rouge_scorer

    ROUGE_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è rouge-score –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install rouge-score")
    ROUGE_AVAILABLE = False

try:
    import nltk
    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

    nltk.download("punkt", quiet=True)
    BLEU_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è NLTK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è BLEU –º–µ—Ç—Ä–∏–∫")
    BLEU_AVAILABLE = False


class ROUGEEvaluator:
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é ROUGE –∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫."""

    def __init__(self, db_path: Path):
        self.db_path = db_path

        if ROUGE_AVAILABLE:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ROUGE scorer
            self.rouge_scorer = rouge_scorer.RougeScorer(
                ["rouge1", "rouge2", "rougeL"], use_stemmer=True
            )

        self.results = {
            "timestamp": datetime.now().isoformat(),
            "metrics_available": {"rouge": ROUGE_AVAILABLE, "bleu": BLEU_AVAILABLE},
        }

    def fetch_data_with_references(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ ROUGE.
        –í –∏–¥–µ–∞–ª–µ –Ω—É–∂–Ω—ã reference summaries, –Ω–æ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫–∞–∫ –ø—Å–µ–≤–¥–æ-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã.
        """
        if not self.db_path.exists():
            print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.db_path}")
            return []

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row

            query = """
            SELECT 
                m.message_id,
                m.text,
                m.channel_id,
                a.summary
            FROM messages m
            JOIN analyses a ON m.message_id = a.message_id
            WHERE m.text IS NOT NULL 
            AND a.summary IS NOT NULL
            AND LENGTH(m.text) > 100
            AND LENGTH(a.summary) > 20
            ORDER BY RANDOM() LIMIT ?
            """

            cursor = conn.execute(query, (limit,))
            rows = cursor.fetchall()
            conn.close()

            data = []
            for row in rows:
                # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å –∏–∑ –ø–µ—Ä–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                text = row["text"]
                sentences = self._split_sentences(text)

                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å
                reference_summary = ". ".join(sentences[: min(3, len(sentences))])

                data.append(
                    {
                        "message_id": row["message_id"],
                        "channel_id": row["channel_id"],
                        "original_text": text,
                        "generated_summary": row["summary"],
                        "reference_summary": reference_summary,
                    }
                )

            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è ROUGE –æ—Ü–µ–Ω–∫–∏")
            return data

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []

    def _split_sentences(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        try:
            import nltk

            sentences = nltk.sent_tokenize(text, language="russian")
        except:
            import re

            sentences = re.split(r"[.!?]+\s+", text)
            sentences = [s.strip() for s in sentences if s.strip()]

        return [s for s in sentences if len(s.split()) >= 5]

    def evaluate_rouge_scores(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç ROUGE –º–µ—Ç—Ä–∏–∫–∏."""
        print(f"\nüîç –û—Ü–µ–Ω–∫–∞ ROUGE –º–µ—Ç—Ä–∏–∫ ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        if not ROUGE_AVAILABLE:
            return {"status": "skipped", "reason": "ROUGE not available"}

        rouge1_scores = {"precision": [], "recall": [], "fmeasure": []}
        rouge2_scores = {"precision": [], "recall": [], "fmeasure": []}
        rougeL_scores = {"precision": [], "recall": [], "fmeasure": []}

        detailed_results = []

        for i, item in enumerate(data):
            if i % 20 == 0 and i > 0:
                print(f"  üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤...")

            generated = item["generated_summary"]
            reference = item["reference_summary"]

            try:
                # –í—ã—á–∏—Å–ª—è–µ–º ROUGE scores
                scores = self.rouge_scorer.score(reference, generated)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º scores
                rouge1_scores["precision"].append(scores["rouge1"].precision)
                rouge1_scores["recall"].append(scores["rouge1"].recall)
                rouge1_scores["fmeasure"].append(scores["rouge1"].fmeasure)

                rouge2_scores["precision"].append(scores["rouge2"].precision)
                rouge2_scores["recall"].append(scores["rouge2"].recall)
                rouge2_scores["fmeasure"].append(scores["rouge2"].fmeasure)

                rougeL_scores["precision"].append(scores["rougeL"].precision)
                rougeL_scores["recall"].append(scores["rougeL"].recall)
                rougeL_scores["fmeasure"].append(scores["rougeL"].fmeasure)

                detailed_results.append(
                    {
                        "message_id": item["message_id"],
                        "rouge1_f": scores["rouge1"].fmeasure,
                        "rouge2_f": scores["rouge2"].fmeasure,
                        "rougeL_f": scores["rougeL"].fmeasure,
                        "generated_length": len(generated.split()),
                        "reference_length": len(reference.split()),
                    }
                )

            except Exception as e:
                print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ ROUGE –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞ {i}: {e}")
                continue

        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if detailed_results:
            aggregated_scores = {
                "rouge1": {
                    "precision": np.mean(rouge1_scores["precision"]),
                    "recall": np.mean(rouge1_scores["recall"]),
                    "fmeasure": np.mean(rouge1_scores["fmeasure"]),
                },
                "rouge2": {
                    "precision": np.mean(rouge2_scores["precision"]),
                    "recall": np.mean(rouge2_scores["recall"]),
                    "fmeasure": np.mean(rouge2_scores["fmeasure"]),
                },
                "rougeL": {
                    "precision": np.mean(rougeL_scores["precision"]),
                    "recall": np.mean(rougeL_scores["recall"]),
                    "fmeasure": np.mean(rougeL_scores["fmeasure"]),
                },
            }

            print(f"  üìä ROUGE-1 F1: {aggregated_scores['rouge1']['fmeasure']:.3f}")
            print(f"  üìä ROUGE-2 F1: {aggregated_scores['rouge2']['fmeasure']:.3f}")
            print(f"  üìä ROUGE-L F1: {aggregated_scores['rougeL']['fmeasure']:.3f}")

            return {
                "status": "passed",
                "samples_evaluated": len(detailed_results),
                "aggregated_scores": aggregated_scores,
                "detailed_results": detailed_results[
                    :10
                ],  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
            }
        else:
            return {"status": "failed", "reason": "No valid ROUGE scores computed"}

    def evaluate_bleu_scores(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç BLEU –º–µ—Ç—Ä–∏–∫–∏."""
        print(f"\nüîç –û—Ü–µ–Ω–∫–∞ BLEU –º–µ—Ç—Ä–∏–∫ ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        if not BLEU_AVAILABLE:
            return {"status": "skipped", "reason": "BLEU not available"}

        bleu_scores = []
        smoothing_function = SmoothingFunction().method1

        for i, item in enumerate(data):
            if i % 20 == 0 and i > 0:
                print(f"  üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤...")

            generated = item["generated_summary"].lower().split()
            reference = item["reference_summary"].lower().split()

            try:
                # –í—ã—á–∏—Å–ª—è–µ–º BLEU score
                bleu_score = sentence_bleu(
                    [reference], generated, smoothing_function=smoothing_function
                )
                bleu_scores.append(bleu_score)

            except Exception as e:
                print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ BLEU –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞ {i}: {e}")
                continue

        if bleu_scores:
            avg_bleu = np.mean(bleu_scores)
            std_bleu = np.std(bleu_scores)

            print(f"  üìä –°—Ä–µ–¥–Ω–∏–π BLEU: {avg_bleu:.3f} (¬±{std_bleu:.3f})")

            return {
                "status": "passed",
                "samples_evaluated": len(bleu_scores),
                "average_bleu": avg_bleu,
                "std_bleu": std_bleu,
                "bleu_scores": bleu_scores[:10],  # –ü–µ—Ä–≤—ã–µ 10
            }
        else:
            return {"status": "failed", "reason": "No valid BLEU scores computed"}

    def evaluate_length_consistency(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª–∏–Ω—ã —Å–∞–º–º–∞—Ä–∏."""
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª–∏–Ω—ã ({len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤)")

        length_ratios = []
        absolute_lengths = []

        for item in data:
            orig_len = len(item["original_text"].split())
            summ_len = len(item["generated_summary"].split())

            if orig_len > 0:
                ratio = summ_len / orig_len
                length_ratios.append(ratio)
                absolute_lengths.append(summ_len)

        if length_ratios:
            stats = {
                "avg_length_ratio": np.mean(length_ratios),
                "std_length_ratio": np.std(length_ratios),
                "avg_absolute_length": np.mean(absolute_lengths),
                "std_absolute_length": np.std(absolute_lengths),
                "min_length": np.min(absolute_lengths),
                "max_length": np.max(absolute_lengths),
            }

            print(f"  üìè –°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª–∏–Ω—ã: {stats['avg_length_ratio']:.3f}")
            print(
                f"  üìù –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–∞–º–º–∞—Ä–∏: {stats['avg_absolute_length']:.1f} —Å–ª–æ–≤"
            )
            print(
                f"  üìä –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª–∏–Ω: {stats['min_length']}-{stats['max_length']} —Å–ª–æ–≤"
            )

            # –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
            anomalies = []
            for i, ratio in enumerate(length_ratios):
                if ratio > 0.8:  # –°–∞–º–º–∞—Ä–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
                    anomalies.append(
                        f"–û–±—Ä–∞–∑–µ—Ü {i}: —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ (ratio: {ratio:.2f})"
                    )
                elif ratio < 0.05:  # –°–∞–º–º–∞—Ä–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ
                    anomalies.append(
                        f"–û–±—Ä–∞–∑–µ—Ü {i}: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (ratio: {ratio:.2f})"
                    )

            if anomalies:
                print(f"  ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {len(anomalies)}")

            return {
                "status": "passed",
                "statistics": stats,
                "anomalies_count": len(anomalies),
                "anomalies": anomalies[:5],  # –ü–µ—Ä–≤—ã–µ 5
            }
        else:
            return {"status": "failed", "reason": "No valid length data"}

    def run_comprehensive_rouge_evaluation(self, samples: int = 100) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å ROUGE –º–µ—Ç—Ä–∏–∫–∞–º–∏."""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π ROUGE –æ—Ü–µ–Ω–∫–∏")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {samples}")
        print("=" * 50)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = self.fetch_data_with_references(samples)

        if not data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return self.results

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
        self.results["rouge_evaluation"] = self.evaluate_rouge_scores(data)
        self.results["bleu_evaluation"] = self.evaluate_bleu_scores(data)
        self.results["length_consistency"] = self.evaluate_length_consistency(data)

        # –ò—Ç–æ–≥–∏
        print("\n" + "=" * 50)
        print("üìã –ò–¢–û–ì–ò ROUGE –û–¶–ï–ù–ö–ò:")

        if self.results["rouge_evaluation"].get("status") == "passed":
            rouge_scores = self.results["rouge_evaluation"]["aggregated_scores"]
            print(f"üìä ROUGE-1 F1: {rouge_scores['rouge1']['fmeasure']:.3f}")
            print(f"üìä ROUGE-2 F1: {rouge_scores['rouge2']['fmeasure']:.3f}")
            print(f"üìä ROUGE-L F1: {rouge_scores['rougeL']['fmeasure']:.3f}")

        if self.results["bleu_evaluation"].get("status") == "passed":
            bleu_score = self.results["bleu_evaluation"]["average_bleu"]
            print(f"üìä BLEU: {bleu_score:.3f}")

        return self.results

    def save_results(self, output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª."""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã
        def convert_numpy_types(obj):
            if hasattr(obj, "item"):  # numpy scalar
                return obj.item()
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(v) for v in obj]
            else:
                return obj

        converted_results = convert_numpy_types(self.results)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(converted_results, f, ensure_ascii=False, indent=2)

        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é ROUGE –º–µ—Ç—Ä–∏–∫"
    )

    parser.add_argument(
        "--samples",
        type=int,
        default=100,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 100)",
    )

    parser.add_argument(
        "--db", type=Path, default=Path("data/storage.db"), help="–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
    )

    parser.add_argument(
        "--output",
        type=Path,
        default=Path("evaluation/rouge_results.json"),
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫
    if not ROUGE_AVAILABLE:
        print("‚ùå –î–ª—è —Ä–∞–±–æ—Ç—ã —Å–∫—Ä–∏–ø—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install rouge-score")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É
    evaluator = ROUGEEvaluator(args.db)
    results = evaluator.run_comprehensive_rouge_evaluation(args.samples)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    evaluator.save_results(args.output)

    print(f"\nüéâ ROUGE –æ—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    main()
